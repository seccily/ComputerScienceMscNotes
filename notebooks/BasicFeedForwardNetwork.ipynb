{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_kYfsAj8kw1"
      },
      "source": [
        "## Task:\n",
        "Get hands-on experience with training a shallow neural network (1- or 2-hidden layers only) on a small but adjustable problem.\n",
        "\n",
        "## Software:\n",
        "\n",
        "You may find the necessary function references here:\n",
        "\n",
        "https://pytorch.org/docs/stable/torch.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfrIB9-JBkmM"
      },
      "source": [
        "## Mount your files (not needed for this homework)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUIt1yDc-KZ5",
        "outputId": "c07d0d69-cae8-4fb8-8cae-84cd53473962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Add in the future if you need to transfer data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hd899eDBxBy"
      },
      "source": [
        "## Include the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjZsRuYGmMnq"
      },
      "outputs": [],
      "source": [
        "#import pytorch\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "#for plotting the learning curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVPEwwzYB7ZF"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ochiJvnN-fwF"
      },
      "outputs": [],
      "source": [
        "# f                 = 2       # target function frequency\n",
        "# max_epochs        = 200_000 # maximum number of epochs\n",
        "# hiddensize        = 50        # number of hidden layers for your network\n",
        "# lr                = 1e-4        # learning rate\n",
        "# momentum          = 0.9        # momentum parameter for SGD optimizer\n",
        "# num_hidden_layers = 2        # number of hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4U_KnhBbAtR"
      },
      "outputs": [],
      "source": [
        "f = 2                                       # target function frequency\n",
        "max_epochs = 200_000                        # maximum number of epochs\n",
        "\n",
        "# defining ranges for hyperparameters\n",
        "hiddensizes = [25, 50, 100]                 # number of hidden layers for your network\n",
        "learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]   # learning rate\n",
        "momentums = [0.9, 0]                        # momentum parameter for SGD optimizer -- 0 is SGD's default momentum\n",
        "num_hidden_layers = [1, 2]                  # number of hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv7lXGuVq8l5"
      },
      "outputs": [],
      "source": [
        "# creating lists of all possible combinations for both SGD and Adam optimizer\n",
        "hparam_list_sgd = list(itertools.product(hiddensizes, learning_rates, num_hidden_layers, momentums))\n",
        "hparam_list_adam = list(itertools.product(hiddensizes, learning_rates, num_hidden_layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOOhlhYLr0Ss",
        "outputId": "ac28fdf6-9eef-4bc3-bb40-c293087e1700"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# number of possible combinations\n",
        "len(hparam_list_sgd) + len(hparam_list_adam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1NE047kCc8D"
      },
      "source": [
        "## Set a random seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ZhbW6A2D5R",
        "outputId": "09579210-e3ec-4b98-d10b-878c0d2bbf61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc4e41db7d0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc_xQE6FDizN"
      },
      "source": [
        "## Generate and plot the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "JEWb9f7PnDfk",
        "outputId": "465bbf42-074a-4f6d-a47c-1bd7a440877f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[37.4540],\n",
            "        [95.0714],\n",
            "        [73.1994],\n",
            "        [59.8658],\n",
            "        [15.6019]])\n",
            "tensor([[-1.0000],\n",
            "        [-0.5854],\n",
            "        [ 0.2289],\n",
            "        [ 0.9445],\n",
            "        [ 0.9254]])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def return_data(num_samples):\n",
        "    '''\n",
        "    Function generates num_samples many instances of (x, sin(2 * pi * f * x)) pairs\n",
        "    '''\n",
        "    x = torch.Tensor(np.random.rand(num_samples, 1) * 100)\n",
        "    y = np.sin(2 * 3.14 * f / 100 * x)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "# Set the number of instances\n",
        "num_train = 50\n",
        "num_test = 50\n",
        "\n",
        "# Generate train and test data\n",
        "x_train, y_train = return_data(num_train)\n",
        "x_test, y_test = return_data(num_test)\n",
        "\n",
        "# Show first 5 instances\n",
        "print(x_train[:5])\n",
        "print(y_train[:5])\n",
        "\n",
        "# Plot the training data\n",
        "plt.scatter(x_train.numpy(), y_train.numpy(), label='Training Data')\n",
        "\n",
        "# Plot the test data\n",
        "plt.scatter(x_test.numpy(), y_test.numpy(), label='Test Data')\n",
        "\n",
        "plt.title(\"Training and Test Data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrd2HWCgD1Hp"
      },
      "source": [
        "## Design a neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNP6fcv7mRmY"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, hidden_dimension, num_hidden_layers):\n",
        "        super(Net, self).__init__()\n",
        "        # input layer\n",
        "        # B x 1 -> B x hidden_dimension (with a ReLU nonlinearity at the end)\n",
        "        self.input = torch.nn.Sequential(\n",
        "            torch.nn.Linear(1, hidden_dimension),\n",
        "            torch.nn.ReLU()\n",
        "        ) # add a sequential layer that contains a Linear layer and ReLU respectively\n",
        "\n",
        "        # hidden layers\n",
        "        # B x hidden_dimension -> B x hidden_dimension (with a ReLU nonlinearity at the end) repeated num_hidden_layers many times\n",
        "        self.hiddens = torch.nn.ModuleList(\n",
        "            [\n",
        "                torch.nn.Sequential(\n",
        "                    torch.nn.Linear(hidden_dimension, hidden_dimension),\n",
        "                    torch.nn.ReLU()\n",
        "                )\n",
        "                for num in range(num_hidden_layers)\n",
        "            ]\n",
        "        ) # add a ModuleList that contains num_hidden_layers many sequential layers each having one Linear layer and one ReLU\n",
        "\n",
        "        # output layer\n",
        "        # B x hidden_dimension -> B x 1\n",
        "        self.output = torch.nn.Linear(hidden_dimension, 1) # add a Linear layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input(x)\n",
        "        for hidden in self.hiddens:\n",
        "            x = hidden(x)\n",
        "        x = self.output(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf3vfUf7GJO4"
      },
      "source": [
        "## Create a network, loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkV8r21MmS0e"
      },
      "outputs": [],
      "source": [
        "# function for network, loss func and optimizer initializations\n",
        "\n",
        "# takes hiddensize, number of hidden layers, desired optimizer as str,\n",
        "# learning rate and momentum as input parameters to use in inits\n",
        "\n",
        "# returns created network, objective and optimizer\n",
        "\n",
        "def create_net_loss_optim(\n",
        "    hiddensize,\n",
        "    num_hidden_layers,\n",
        "    desired_optimizer,\n",
        "    lr,\n",
        "    momentum=0.0):\n",
        "\n",
        "    # Create the neural network and specify the loss function and optimizer\n",
        "    net = Net(hiddensize, num_hidden_layers)# create a network with hidden_dimension and num_hidden_layers\n",
        "\n",
        "    criterion = torch.nn.MSELoss() # objective to minimize\n",
        "\n",
        "    if desired_optimizer == \"adam\":\n",
        "        optimizer = torch.optim.Adam(net.parameters(), lr=lr) # choose and create an optimizer (SGD, SGD with momentum, or ADAM)\n",
        "    else: # if the desired optimizer is SGD\n",
        "        optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    return net, criterion, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftAMe0YyGO6J"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGm00oGYnGK8"
      },
      "outputs": [],
      "source": [
        "# function for training\n",
        "\n",
        "# takes train dataset, objective to minimize, optimizer and model as inputs\n",
        "\n",
        "# returns calculated train losses, validation losses, number of epochs that\n",
        "# model was trained on and the final model\n",
        "\n",
        "def _train(x_train, y_train, criterion, optimizer, model):\n",
        "\n",
        "    # Train the neural network\n",
        "\n",
        "    # Set the desired error threshold\n",
        "    # acceptable for the sine function\n",
        "    error_threshold = 0.001\n",
        "\n",
        "    # To display the learning curve\n",
        "    losses = []\n",
        "    vallosses = []\n",
        "\n",
        "    epoch = 0\n",
        "\n",
        "    while epoch < max_epochs:\n",
        "        epoch += 1\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(x_train)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(y_pred, y_train)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # Make an evaluation on the test set every 100 epochs\n",
        "        if epoch % 100 == 0:\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Test the neural network with val data\n",
        "            with torch.no_grad():\n",
        "                y_pred = model(x_test)\n",
        "\n",
        "            valloss = criterion(y_pred, y_test) # loss in the test set\n",
        "            vallosses.append(valloss.item())\n",
        "\n",
        "            # Print the loss every 1000 epochs\n",
        "            if epoch % 10000 == 0:\n",
        "                print(\"Epoch {}: Loss = {}\".format(epoch, loss.item()))\n",
        "                print('\\nValidation loss:', valloss, '\\n')\n",
        "\n",
        "            # Check if the error is below the threshold\n",
        "            if loss < error_threshold or epoch > 200000:\n",
        "                break\n",
        "\n",
        "    return losses, vallosses, epoch, model\n",
        "\n",
        "    #end of the epoch loop ------------------------------------------------\n",
        "\n",
        "    # Plot the learning curve\n",
        "    # plt.plot(losses)\n",
        "    # plt.plot(vallosses)\n",
        "    # plt.title(\"Learning Curve\")\n",
        "    # plt.xlabel(\"Epoch\")\n",
        "    # plt.ylabel(\"Loss\")\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M9GpjBRev5a"
      },
      "source": [
        "### trainings with various configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76x4phTkr_su"
      },
      "outputs": [],
      "source": [
        "# list for saving the test results\n",
        "\n",
        "results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_we41Ner7pq"
      },
      "source": [
        "####sgd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qILv_5a5tLWM",
        "outputId": "131d2d28-589a-4721-eb47-73e9b184e6b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 0.01, 1, 0.9)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hparam_list_sgd[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhw_gZQ_sARo",
        "outputId": "e7e09d29-117d-4810-e02c-2f154de5bfef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/48 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 20000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 30000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 40000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 50000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 60000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 70000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 80000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 90000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 100000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 110000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 120000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 130000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 140000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 150000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 160000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 170000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 180000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 190000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 1/48 [02:02<1:36:19, 122.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 10000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 20000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 30000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 40000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 50000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 60000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 70000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 80000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 90000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 100000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 110000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 120000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 130000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 140000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 150000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 160000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 170000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 180000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 190000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 2/48 [03:38<1:22:02, 107.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 10000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 20000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 30000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 40000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 50000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 60000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 70000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 80000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 90000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 100000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 110000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 120000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 130000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 140000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 150000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 160000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 170000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 180000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 190000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 3/48 [05:55<1:30:33, 120.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 10000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 20000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 30000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 40000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 50000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 60000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 70000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 80000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 90000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 100000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 110000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 120000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 130000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 140000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 150000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 160000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 170000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 180000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 190000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 4/48 [07:49<1:26:31, 117.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5152) \n",
            "\n",
            "Epoch 10000: Loss = 0.3945022523403168\n",
            "\n",
            "Validation loss: tensor(0.3968) \n",
            "\n",
            "Epoch 20000: Loss = 0.39431554079055786\n",
            "\n",
            "Validation loss: tensor(0.3928) \n",
            "\n",
            "Epoch 30000: Loss = 0.3942033350467682\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 40000: Loss = 0.39419448375701904\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 50000: Loss = 0.39419329166412354\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 60000: Loss = 0.39419281482696533\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 70000: Loss = 0.39419272541999817\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 80000: Loss = 0.39419615268707275\n",
            "\n",
            "Validation loss: tensor(0.3950) \n",
            "\n",
            "Epoch 90000: Loss = 0.3941938877105713\n",
            "\n",
            "Validation loss: tensor(0.3948) \n",
            "\n",
            "Epoch 100000: Loss = 0.39419347047805786\n",
            "\n",
            "Validation loss: tensor(0.3948) \n",
            "\n",
            "Epoch 110000: Loss = 0.3941933512687683\n",
            "\n",
            "Validation loss: tensor(0.3947) \n",
            "\n",
            "Epoch 120000: Loss = 0.3941928446292877\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 130000: Loss = 0.39419296383857727\n",
            "\n",
            "Validation loss: tensor(0.3947) \n",
            "\n",
            "Epoch 140000: Loss = 0.39419305324554443\n",
            "\n",
            "Validation loss: tensor(0.3947) \n",
            "\n",
            "Epoch 150000: Loss = 0.39419272541999817\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 160000: Loss = 0.39419278502464294\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 170000: Loss = 0.39419278502464294\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 180000: Loss = 0.39419278502464294\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 190000: Loss = 0.39419278502464294\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 5/48 [09:40<1:22:48, 115.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.39419278502464294\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 10000: Loss = 0.36001941561698914\n",
            "\n",
            "Validation loss: tensor(0.3554) \n",
            "\n",
            "Epoch 20000: Loss = 0.34247997403144836\n",
            "\n",
            "Validation loss: tensor(0.3392) \n",
            "\n",
            "Epoch 30000: Loss = 0.32101118564605713\n",
            "\n",
            "Validation loss: tensor(0.3141) \n",
            "\n",
            "Epoch 40000: Loss = 0.3102777302265167\n",
            "\n",
            "Validation loss: tensor(0.2997) \n",
            "\n",
            "Epoch 50000: Loss = 0.309563547372818\n",
            "\n",
            "Validation loss: tensor(0.2967) \n",
            "\n",
            "Epoch 60000: Loss = 0.3093684911727905\n",
            "\n",
            "Validation loss: tensor(0.2962) \n",
            "\n",
            "Epoch 70000: Loss = 0.3093079626560211\n",
            "\n",
            "Validation loss: tensor(0.2960) \n",
            "\n",
            "Epoch 80000: Loss = 0.30927976965904236\n",
            "\n",
            "Validation loss: tensor(0.2959) \n",
            "\n",
            "Epoch 90000: Loss = 0.30925747752189636\n",
            "\n",
            "Validation loss: tensor(0.2958) \n",
            "\n",
            "Epoch 100000: Loss = 0.3092357814311981\n",
            "\n",
            "Validation loss: tensor(0.2957) \n",
            "\n",
            "Epoch 110000: Loss = 0.3092096447944641\n",
            "\n",
            "Validation loss: tensor(0.2957) \n",
            "\n",
            "Epoch 120000: Loss = 0.30918699502944946\n",
            "\n",
            "Validation loss: tensor(0.2956) \n",
            "\n",
            "Epoch 130000: Loss = 0.30916550755500793\n",
            "\n",
            "Validation loss: tensor(0.2956) \n",
            "\n",
            "Epoch 140000: Loss = 0.30914485454559326\n",
            "\n",
            "Validation loss: tensor(0.2956) \n",
            "\n",
            "Epoch 150000: Loss = 0.3091279864311218\n",
            "\n",
            "Validation loss: tensor(0.2955) \n",
            "\n",
            "Epoch 160000: Loss = 0.3091140687465668\n",
            "\n",
            "Validation loss: tensor(0.2955) \n",
            "\n",
            "Epoch 170000: Loss = 0.30910101532936096\n",
            "\n",
            "Validation loss: tensor(0.2954) \n",
            "\n",
            "Epoch 180000: Loss = 0.3090888559818268\n",
            "\n",
            "Validation loss: tensor(0.2954) \n",
            "\n",
            "Epoch 190000: Loss = 0.3090774416923523\n",
            "\n",
            "Validation loss: tensor(0.2953) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 6/48 [11:15<1:15:59, 108.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.30906689167022705\n",
            "\n",
            "Validation loss: tensor(0.2953) \n",
            "\n",
            "Epoch 10000: Loss = 0.30794334411621094\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 20000: Loss = 0.3078967034816742\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 30000: Loss = 0.30789467692375183\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 40000: Loss = 0.30789321660995483\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 50000: Loss = 0.3078921139240265\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 60000: Loss = 0.3078910708427429\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 70000: Loss = 0.307890385389328\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 80000: Loss = 0.30788958072662354\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 90000: Loss = 0.30788901448249817\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 100000: Loss = 0.30788856744766235\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 110000: Loss = 0.30788829922676086\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 120000: Loss = 0.30788809061050415\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 130000: Loss = 0.30788809061050415\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 140000: Loss = 0.30788806080818176\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 150000: Loss = 0.3078879415988922\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 160000: Loss = 0.3078876733779907\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 170000: Loss = 0.3078877627849579\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 180000: Loss = 0.3078877329826355\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 190000: Loss = 0.3078875243663788\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 7/48 [13:29<1:19:40, 116.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.30788758397102356\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 10000: Loss = 0.3693407475948334\n",
            "\n",
            "Validation loss: tensor(0.3630) \n",
            "\n",
            "Epoch 20000: Loss = 0.340862512588501\n",
            "\n",
            "Validation loss: tensor(0.3482) \n",
            "\n",
            "Epoch 30000: Loss = 0.2557228207588196\n",
            "\n",
            "Validation loss: tensor(0.2665) \n",
            "\n",
            "Epoch 40000: Loss = 0.21549850702285767\n",
            "\n",
            "Validation loss: tensor(0.3563) \n",
            "\n",
            "Epoch 50000: Loss = 0.19760024547576904\n",
            "\n",
            "Validation loss: tensor(0.1123) \n",
            "\n",
            "Epoch 60000: Loss = 0.06089398264884949\n",
            "\n",
            "Validation loss: tensor(0.0822) \n",
            "\n",
            "Epoch 70000: Loss = 0.050598446279764175\n",
            "\n",
            "Validation loss: tensor(0.0638) \n",
            "\n",
            "Epoch 80000: Loss = 0.04559004679322243\n",
            "\n",
            "Validation loss: tensor(0.0689) \n",
            "\n",
            "Epoch 90000: Loss = 0.07980319857597351\n",
            "\n",
            "Validation loss: tensor(0.0658) \n",
            "\n",
            "Epoch 100000: Loss = 0.03595271334052086\n",
            "\n",
            "Validation loss: tensor(0.0631) \n",
            "\n",
            "Epoch 110000: Loss = 0.028247861191630363\n",
            "\n",
            "Validation loss: tensor(0.0475) \n",
            "\n",
            "Epoch 120000: Loss = 0.0373493991792202\n",
            "\n",
            "Validation loss: tensor(0.0688) \n",
            "\n",
            "Epoch 130000: Loss = 0.03690986707806587\n",
            "\n",
            "Validation loss: tensor(0.0627) \n",
            "\n",
            "Epoch 140000: Loss = 0.03373907506465912\n",
            "\n",
            "Validation loss: tensor(0.0586) \n",
            "\n",
            "Epoch 150000: Loss = 0.03251634165644646\n",
            "\n",
            "Validation loss: tensor(0.0628) \n",
            "\n",
            "Epoch 160000: Loss = 0.03253883123397827\n",
            "\n",
            "Validation loss: tensor(0.0603) \n",
            "\n",
            "Epoch 170000: Loss = 0.0302102193236351\n",
            "\n",
            "Validation loss: tensor(0.0498) \n",
            "\n",
            "Epoch 180000: Loss = 0.026524841785430908\n",
            "\n",
            "Validation loss: tensor(0.0450) \n",
            "\n",
            "Epoch 190000: Loss = 0.025691406801342964\n",
            "\n",
            "Validation loss: tensor(0.0434) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 8/48 [15:21<1:16:54, 115.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.027267005294561386\n",
            "\n",
            "Validation loss: tensor(0.0476) \n",
            "\n",
            "Epoch 10000: Loss = 0.3969607949256897\n",
            "\n",
            "Validation loss: tensor(0.4008) \n",
            "\n",
            "Epoch 20000: Loss = 0.39688706398010254\n",
            "\n",
            "Validation loss: tensor(0.4006) \n",
            "\n",
            "Epoch 30000: Loss = 0.39681997895240784\n",
            "\n",
            "Validation loss: tensor(0.4004) \n",
            "\n",
            "Epoch 40000: Loss = 0.39673805236816406\n",
            "\n",
            "Validation loss: tensor(0.4002) \n",
            "\n",
            "Epoch 50000: Loss = 0.3966215252876282\n",
            "\n",
            "Validation loss: tensor(0.4001) \n",
            "\n",
            "Epoch 60000: Loss = 0.39649704098701477\n",
            "\n",
            "Validation loss: tensor(0.3999) \n",
            "\n",
            "Epoch 70000: Loss = 0.39637523889541626\n",
            "\n",
            "Validation loss: tensor(0.3996) \n",
            "\n",
            "Epoch 80000: Loss = 0.3962542712688446\n",
            "\n",
            "Validation loss: tensor(0.3994) \n",
            "\n",
            "Epoch 90000: Loss = 0.39612847566604614\n",
            "\n",
            "Validation loss: tensor(0.3991) \n",
            "\n",
            "Epoch 100000: Loss = 0.39599892497062683\n",
            "\n",
            "Validation loss: tensor(0.3988) \n",
            "\n",
            "Epoch 110000: Loss = 0.395865261554718\n",
            "\n",
            "Validation loss: tensor(0.3986) \n",
            "\n",
            "Epoch 120000: Loss = 0.3957260549068451\n",
            "\n",
            "Validation loss: tensor(0.3983) \n",
            "\n",
            "Epoch 130000: Loss = 0.3955788314342499\n",
            "\n",
            "Validation loss: tensor(0.3980) \n",
            "\n",
            "Epoch 140000: Loss = 0.39542457461357117\n",
            "\n",
            "Validation loss: tensor(0.3976) \n",
            "\n",
            "Epoch 150000: Loss = 0.39527079463005066\n",
            "\n",
            "Validation loss: tensor(0.3974) \n",
            "\n",
            "Epoch 160000: Loss = 0.39512065052986145\n",
            "\n",
            "Validation loss: tensor(0.3971) \n",
            "\n",
            "Epoch 170000: Loss = 0.3949776589870453\n",
            "\n",
            "Validation loss: tensor(0.3968) \n",
            "\n",
            "Epoch 180000: Loss = 0.39484652876853943\n",
            "\n",
            "Validation loss: tensor(0.3965) \n",
            "\n",
            "Epoch 190000: Loss = 0.39473018050193787\n",
            "\n",
            "Validation loss: tensor(0.3962) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 9/48 [17:09<1:13:27, 113.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.39463168382644653\n",
            "\n",
            "Validation loss: tensor(0.3960) \n",
            "\n",
            "Epoch 10000: Loss = 0.39433783292770386\n",
            "\n",
            "Validation loss: tensor(0.3892) \n",
            "\n",
            "Epoch 20000: Loss = 0.3833038806915283\n",
            "\n",
            "Validation loss: tensor(0.3830) \n",
            "\n",
            "Epoch 30000: Loss = 0.37971627712249756\n",
            "\n",
            "Validation loss: tensor(0.3803) \n",
            "\n",
            "Epoch 40000: Loss = 0.3765382468700409\n",
            "\n",
            "Validation loss: tensor(0.3769) \n",
            "\n",
            "Epoch 50000: Loss = 0.37340420484542847\n",
            "\n",
            "Validation loss: tensor(0.3737) \n",
            "\n",
            "Epoch 60000: Loss = 0.3705175817012787\n",
            "\n",
            "Validation loss: tensor(0.3697) \n",
            "\n",
            "Epoch 70000: Loss = 0.3680132031440735\n",
            "\n",
            "Validation loss: tensor(0.3665) \n",
            "\n",
            "Epoch 80000: Loss = 0.36596810817718506\n",
            "\n",
            "Validation loss: tensor(0.3637) \n",
            "\n",
            "Epoch 90000: Loss = 0.36423835158348083\n",
            "\n",
            "Validation loss: tensor(0.3614) \n",
            "\n",
            "Epoch 100000: Loss = 0.36302316188812256\n",
            "\n",
            "Validation loss: tensor(0.3597) \n",
            "\n",
            "Epoch 110000: Loss = 0.36219435930252075\n",
            "\n",
            "Validation loss: tensor(0.3582) \n",
            "\n",
            "Epoch 120000: Loss = 0.3615591526031494\n",
            "\n",
            "Validation loss: tensor(0.3582) \n",
            "\n",
            "Epoch 130000: Loss = 0.3611902892589569\n",
            "\n",
            "Validation loss: tensor(0.3561) \n",
            "\n",
            "Epoch 140000: Loss = 0.36084914207458496\n",
            "\n",
            "Validation loss: tensor(0.3556) \n",
            "\n",
            "Epoch 150000: Loss = 0.3607352375984192\n",
            "\n",
            "Validation loss: tensor(0.3550) \n",
            "\n",
            "Epoch 160000: Loss = 0.36052340269088745\n",
            "\n",
            "Validation loss: tensor(0.3568) \n",
            "\n",
            "Epoch 170000: Loss = 0.36045700311660767\n",
            "\n",
            "Validation loss: tensor(0.3567) \n",
            "\n",
            "Epoch 180000: Loss = 0.36045441031455994\n",
            "\n",
            "Validation loss: tensor(0.3541) \n",
            "\n",
            "Epoch 190000: Loss = 0.3604907989501953\n",
            "\n",
            "Validation loss: tensor(0.3540) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 10/48 [18:42<1:07:43, 106.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.36033231019973755\n",
            "\n",
            "Validation loss: tensor(0.3563) \n",
            "\n",
            "Epoch 10000: Loss = 0.38546642661094666\n",
            "\n",
            "Validation loss: tensor(0.3859) \n",
            "\n",
            "Epoch 20000: Loss = 0.3546034097671509\n",
            "\n",
            "Validation loss: tensor(0.3526) \n",
            "\n",
            "Epoch 30000: Loss = 0.26704952120780945\n",
            "\n",
            "Validation loss: tensor(0.2828) \n",
            "\n",
            "Epoch 40000: Loss = 0.08833051472902298\n",
            "\n",
            "Validation loss: tensor(0.1017) \n",
            "\n",
            "Epoch 50000: Loss = 0.03244292736053467\n",
            "\n",
            "Validation loss: tensor(0.0513) \n",
            "\n",
            "Epoch 60000: Loss = 0.02521095983684063\n",
            "\n",
            "Validation loss: tensor(0.0394) \n",
            "\n",
            "Epoch 70000: Loss = 0.018956512212753296\n",
            "\n",
            "Validation loss: tensor(0.0306) \n",
            "\n",
            "Epoch 80000: Loss = 0.013302160426974297\n",
            "\n",
            "Validation loss: tensor(0.0238) \n",
            "\n",
            "Epoch 90000: Loss = 0.04527048021554947\n",
            "\n",
            "Validation loss: tensor(0.0734) \n",
            "\n",
            "Epoch 100000: Loss = 0.04520369693636894\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 110000: Loss = 0.04517892003059387\n",
            "\n",
            "Validation loss: tensor(0.0731) \n",
            "\n",
            "Epoch 120000: Loss = 0.04516470804810524\n",
            "\n",
            "Validation loss: tensor(0.0725) \n",
            "\n",
            "Epoch 130000: Loss = 0.04515324905514717\n",
            "\n",
            "Validation loss: tensor(0.0719) \n",
            "\n",
            "Epoch 140000: Loss = 0.045142680406570435\n",
            "\n",
            "Validation loss: tensor(0.0714) \n",
            "\n",
            "Epoch 150000: Loss = 0.04282299429178238\n",
            "\n",
            "Validation loss: tensor(0.0689) \n",
            "\n",
            "Epoch 160000: Loss = 0.042245205491781235\n",
            "\n",
            "Validation loss: tensor(0.0686) \n",
            "\n",
            "Epoch 170000: Loss = 0.04217413067817688\n",
            "\n",
            "Validation loss: tensor(0.0686) \n",
            "\n",
            "Epoch 180000: Loss = 0.04215751588344574\n",
            "\n",
            "Validation loss: tensor(0.0686) \n",
            "\n",
            "Epoch 190000: Loss = 0.04214879870414734\n",
            "\n",
            "Validation loss: tensor(0.0686) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 11/48 [20:53<1:10:19, 114.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.04214119911193848\n",
            "\n",
            "Validation loss: tensor(0.0686) \n",
            "\n",
            "Epoch 10000: Loss = 0.4019466042518616\n",
            "\n",
            "Validation loss: tensor(0.3982) \n",
            "\n",
            "Epoch 20000: Loss = 0.39480772614479065\n",
            "\n",
            "Validation loss: tensor(0.3949) \n",
            "\n",
            "Epoch 30000: Loss = 0.3934076428413391\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 40000: Loss = 0.3925034999847412\n",
            "\n",
            "Validation loss: tensor(0.3940) \n",
            "\n",
            "Epoch 50000: Loss = 0.39155828952789307\n",
            "\n",
            "Validation loss: tensor(0.3932) \n",
            "\n",
            "Epoch 60000: Loss = 0.3904871344566345\n",
            "\n",
            "Validation loss: tensor(0.3920) \n",
            "\n",
            "Epoch 70000: Loss = 0.38925403356552124\n",
            "\n",
            "Validation loss: tensor(0.3907) \n",
            "\n",
            "Epoch 80000: Loss = 0.38783589005470276\n",
            "\n",
            "Validation loss: tensor(0.3892) \n",
            "\n",
            "Epoch 90000: Loss = 0.38620367646217346\n",
            "\n",
            "Validation loss: tensor(0.3874) \n",
            "\n",
            "Epoch 100000: Loss = 0.38433465361595154\n",
            "\n",
            "Validation loss: tensor(0.3854) \n",
            "\n",
            "Epoch 110000: Loss = 0.38217881321907043\n",
            "\n",
            "Validation loss: tensor(0.3830) \n",
            "\n",
            "Epoch 120000: Loss = 0.37970274686813354\n",
            "\n",
            "Validation loss: tensor(0.3804) \n",
            "\n",
            "Epoch 130000: Loss = 0.3768766522407532\n",
            "\n",
            "Validation loss: tensor(0.3776) \n",
            "\n",
            "Epoch 140000: Loss = 0.3737218379974365\n",
            "\n",
            "Validation loss: tensor(0.3744) \n",
            "\n",
            "Epoch 150000: Loss = 0.37022632360458374\n",
            "\n",
            "Validation loss: tensor(0.3706) \n",
            "\n",
            "Epoch 160000: Loss = 0.36639031767845154\n",
            "\n",
            "Validation loss: tensor(0.3663) \n",
            "\n",
            "Epoch 170000: Loss = 0.3622239828109741\n",
            "\n",
            "Validation loss: tensor(0.3620) \n",
            "\n",
            "Epoch 180000: Loss = 0.35768014192581177\n",
            "\n",
            "Validation loss: tensor(0.3569) \n",
            "\n",
            "Epoch 190000: Loss = 0.3527336120605469\n",
            "\n",
            "Validation loss: tensor(0.3518) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 12/48 [22:44<1:07:52, 113.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.3472211956977844\n",
            "\n",
            "Validation loss: tensor(0.3466) \n",
            "\n",
            "Epoch 10000: Loss = 0.3943589925765991\n",
            "\n",
            "Validation loss: tensor(0.3891) \n",
            "\n",
            "Epoch 20000: Loss = 0.3833223283290863\n",
            "\n",
            "Validation loss: tensor(0.3832) \n",
            "\n",
            "Epoch 30000: Loss = 0.3797168433666229\n",
            "\n",
            "Validation loss: tensor(0.3805) \n",
            "\n",
            "Epoch 40000: Loss = 0.37650954723358154\n",
            "\n",
            "Validation loss: tensor(0.3771) \n",
            "\n",
            "Epoch 50000: Loss = 0.3733968436717987\n",
            "\n",
            "Validation loss: tensor(0.3734) \n",
            "\n",
            "Epoch 60000: Loss = 0.3705131411552429\n",
            "\n",
            "Validation loss: tensor(0.3699) \n",
            "\n",
            "Epoch 70000: Loss = 0.367976576089859\n",
            "\n",
            "Validation loss: tensor(0.3666) \n",
            "\n",
            "Epoch 80000: Loss = 0.36588069796562195\n",
            "\n",
            "Validation loss: tensor(0.3640) \n",
            "\n",
            "Epoch 90000: Loss = 0.3642192780971527\n",
            "\n",
            "Validation loss: tensor(0.3618) \n",
            "\n",
            "Epoch 100000: Loss = 0.36298447847366333\n",
            "\n",
            "Validation loss: tensor(0.3600) \n",
            "\n",
            "Epoch 110000: Loss = 0.3620983064174652\n",
            "\n",
            "Validation loss: tensor(0.3587) \n",
            "\n",
            "Epoch 120000: Loss = 0.361487478017807\n",
            "\n",
            "Validation loss: tensor(0.3578) \n",
            "\n",
            "Epoch 130000: Loss = 0.36107367277145386\n",
            "\n",
            "Validation loss: tensor(0.3569) \n",
            "\n",
            "Epoch 140000: Loss = 0.3608059585094452\n",
            "\n",
            "Validation loss: tensor(0.3563) \n",
            "\n",
            "Epoch 150000: Loss = 0.3606245517730713\n",
            "\n",
            "Validation loss: tensor(0.3560) \n",
            "\n",
            "Epoch 160000: Loss = 0.3605157732963562\n",
            "\n",
            "Validation loss: tensor(0.3555) \n",
            "\n",
            "Epoch 170000: Loss = 0.3604353368282318\n",
            "\n",
            "Validation loss: tensor(0.3554) \n",
            "\n",
            "Epoch 180000: Loss = 0.3603811264038086\n",
            "\n",
            "Validation loss: tensor(0.3552) \n",
            "\n",
            "Epoch 190000: Loss = 0.36034679412841797\n",
            "\n",
            "Validation loss: tensor(0.3552) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 13/48 [24:29<1:04:39, 110.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.3603074550628662\n",
            "\n",
            "Validation loss: tensor(0.3548) \n",
            "\n",
            "Epoch 10000: Loss = 0.4666981101036072\n",
            "\n",
            "Validation loss: tensor(0.4461) \n",
            "\n",
            "Epoch 20000: Loss = 0.44986265897750854\n",
            "\n",
            "Validation loss: tensor(0.4321) \n",
            "\n",
            "Epoch 30000: Loss = 0.4365675747394562\n",
            "\n",
            "Validation loss: tensor(0.4211) \n",
            "\n",
            "Epoch 40000: Loss = 0.42605820298194885\n",
            "\n",
            "Validation loss: tensor(0.4128) \n",
            "\n",
            "Epoch 50000: Loss = 0.4177328944206238\n",
            "\n",
            "Validation loss: tensor(0.4063) \n",
            "\n",
            "Epoch 60000: Loss = 0.4108700156211853\n",
            "\n",
            "Validation loss: tensor(0.4005) \n",
            "\n",
            "Epoch 70000: Loss = 0.40525463223457336\n",
            "\n",
            "Validation loss: tensor(0.3963) \n",
            "\n",
            "Epoch 80000: Loss = 0.40078040957450867\n",
            "\n",
            "Validation loss: tensor(0.3932) \n",
            "\n",
            "Epoch 90000: Loss = 0.39721620082855225\n",
            "\n",
            "Validation loss: tensor(0.3908) \n",
            "\n",
            "Epoch 100000: Loss = 0.39433151483535767\n",
            "\n",
            "Validation loss: tensor(0.3891) \n",
            "\n",
            "Epoch 110000: Loss = 0.39202407002449036\n",
            "\n",
            "Validation loss: tensor(0.3877) \n",
            "\n",
            "Epoch 120000: Loss = 0.3901703655719757\n",
            "\n",
            "Validation loss: tensor(0.3866) \n",
            "\n",
            "Epoch 130000: Loss = 0.3886754512786865\n",
            "\n",
            "Validation loss: tensor(0.3858) \n",
            "\n",
            "Epoch 140000: Loss = 0.38745811581611633\n",
            "\n",
            "Validation loss: tensor(0.3852) \n",
            "\n",
            "Epoch 150000: Loss = 0.3864566385746002\n",
            "\n",
            "Validation loss: tensor(0.3847) \n",
            "\n",
            "Epoch 160000: Loss = 0.38562262058258057\n",
            "\n",
            "Validation loss: tensor(0.3843) \n",
            "\n",
            "Epoch 170000: Loss = 0.3849147856235504\n",
            "\n",
            "Validation loss: tensor(0.3840) \n",
            "\n",
            "Epoch 180000: Loss = 0.38430577516555786\n",
            "\n",
            "Validation loss: tensor(0.3837) \n",
            "\n",
            "Epoch 190000: Loss = 0.38376864790916443\n",
            "\n",
            "Validation loss: tensor(0.3834) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 14/48 [26:01<59:35, 105.17s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.38328734040260315\n",
            "\n",
            "Validation loss: tensor(0.3832) \n",
            "\n",
            "Epoch 10000: Loss = 0.40186169743537903\n",
            "\n",
            "Validation loss: tensor(0.3981) \n",
            "\n",
            "Epoch 20000: Loss = 0.3947747051715851\n",
            "\n",
            "Validation loss: tensor(0.3948) \n",
            "\n",
            "Epoch 30000: Loss = 0.3934456706047058\n",
            "\n",
            "Validation loss: tensor(0.3946) \n",
            "\n",
            "Epoch 40000: Loss = 0.39268606901168823\n",
            "\n",
            "Validation loss: tensor(0.3941) \n",
            "\n",
            "Epoch 50000: Loss = 0.3919001817703247\n",
            "\n",
            "Validation loss: tensor(0.3934) \n",
            "\n",
            "Epoch 60000: Loss = 0.3910124599933624\n",
            "\n",
            "Validation loss: tensor(0.3924) \n",
            "\n",
            "Epoch 70000: Loss = 0.38999393582344055\n",
            "\n",
            "Validation loss: tensor(0.3912) \n",
            "\n",
            "Epoch 80000: Loss = 0.38882365822792053\n",
            "\n",
            "Validation loss: tensor(0.3899) \n",
            "\n",
            "Epoch 90000: Loss = 0.3874841332435608\n",
            "\n",
            "Validation loss: tensor(0.3884) \n",
            "\n",
            "Epoch 100000: Loss = 0.3859573006629944\n",
            "\n",
            "Validation loss: tensor(0.3866) \n",
            "\n",
            "Epoch 110000: Loss = 0.3842198848724365\n",
            "\n",
            "Validation loss: tensor(0.3846) \n",
            "\n",
            "Epoch 120000: Loss = 0.3822484612464905\n",
            "\n",
            "Validation loss: tensor(0.3824) \n",
            "\n",
            "Epoch 130000: Loss = 0.38003113865852356\n",
            "\n",
            "Validation loss: tensor(0.3800) \n",
            "\n",
            "Epoch 140000: Loss = 0.37755072116851807\n",
            "\n",
            "Validation loss: tensor(0.3774) \n",
            "\n",
            "Epoch 150000: Loss = 0.3748365342617035\n",
            "\n",
            "Validation loss: tensor(0.3743) \n",
            "\n",
            "Epoch 160000: Loss = 0.3719128370285034\n",
            "\n",
            "Validation loss: tensor(0.3710) \n",
            "\n",
            "Epoch 170000: Loss = 0.36878493428230286\n",
            "\n",
            "Validation loss: tensor(0.3674) \n",
            "\n",
            "Epoch 180000: Loss = 0.365497887134552\n",
            "\n",
            "Validation loss: tensor(0.3635) \n",
            "\n",
            "Epoch 190000: Loss = 0.3618701100349426\n",
            "\n",
            "Validation loss: tensor(0.3593) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 15/48 [28:11<1:01:50, 112.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.35788699984550476\n",
            "\n",
            "Validation loss: tensor(0.3548) \n",
            "\n",
            "Epoch 10000: Loss = 0.44562870264053345\n",
            "\n",
            "Validation loss: tensor(0.4316) \n",
            "\n",
            "Epoch 20000: Loss = 0.436535120010376\n",
            "\n",
            "Validation loss: tensor(0.4241) \n",
            "\n",
            "Epoch 30000: Loss = 0.4288980960845947\n",
            "\n",
            "Validation loss: tensor(0.4181) \n",
            "\n",
            "Epoch 40000: Loss = 0.42286550998687744\n",
            "\n",
            "Validation loss: tensor(0.4135) \n",
            "\n",
            "Epoch 50000: Loss = 0.4178451597690582\n",
            "\n",
            "Validation loss: tensor(0.4097) \n",
            "\n",
            "Epoch 60000: Loss = 0.41365230083465576\n",
            "\n",
            "Validation loss: tensor(0.4064) \n",
            "\n",
            "Epoch 70000: Loss = 0.4085790514945984\n",
            "\n",
            "Validation loss: tensor(0.4025) \n",
            "\n",
            "Epoch 80000: Loss = 0.4058705270290375\n",
            "\n",
            "Validation loss: tensor(0.4007) \n",
            "\n",
            "Epoch 90000: Loss = 0.4036544859409332\n",
            "\n",
            "Validation loss: tensor(0.3993) \n",
            "\n",
            "Epoch 100000: Loss = 0.4018426239490509\n",
            "\n",
            "Validation loss: tensor(0.3981) \n",
            "\n",
            "Epoch 110000: Loss = 0.40036314725875854\n",
            "\n",
            "Validation loss: tensor(0.3973) \n",
            "\n",
            "Epoch 120000: Loss = 0.3991550803184509\n",
            "\n",
            "Validation loss: tensor(0.3966) \n",
            "\n",
            "Epoch 130000: Loss = 0.39817091822624207\n",
            "\n",
            "Validation loss: tensor(0.3961) \n",
            "\n",
            "Epoch 140000: Loss = 0.39736491441726685\n",
            "\n",
            "Validation loss: tensor(0.3957) \n",
            "\n",
            "Epoch 150000: Loss = 0.3967028558254242\n",
            "\n",
            "Validation loss: tensor(0.3954) \n",
            "\n",
            "Epoch 160000: Loss = 0.3961648643016815\n",
            "\n",
            "Validation loss: tensor(0.3952) \n",
            "\n",
            "Epoch 170000: Loss = 0.3957231938838959\n",
            "\n",
            "Validation loss: tensor(0.3951) \n",
            "\n",
            "Epoch 180000: Loss = 0.395353764295578\n",
            "\n",
            "Validation loss: tensor(0.3950) \n",
            "\n",
            "Epoch 190000: Loss = 0.3950473368167877\n",
            "\n",
            "Validation loss: tensor(0.3949) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 16/48 [30:00<59:33, 111.67s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.39479005336761475\n",
            "\n",
            "Validation loss: tensor(0.3948) \n",
            "\n",
            "Epoch 10000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 20000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 30000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 40000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 50000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 60000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 70000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 80000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 90000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 100000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 110000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 120000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 130000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 140000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 150000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 160000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 170000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 180000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 190000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 17/48 [31:57<58:28, 113.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 10000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 20000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 30000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 40000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 50000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 60000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 70000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 80000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 90000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 100000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 110000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 120000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 130000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 140000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 150000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 160000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 170000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 180000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 190000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 18/48 [33:33<53:57, 107.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 10000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 20000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 30000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 40000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 50000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 60000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 70000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 80000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 90000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 100000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 110000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 120000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 130000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 140000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 150000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 160000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 170000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 180000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 190000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 19/48 [35:54<57:01, 117.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 10000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 20000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 30000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 40000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 50000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 60000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 70000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 80000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 90000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 100000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 110000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 120000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 130000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 140000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 150000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 160000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 170000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 180000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 190000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 20/48 [37:50<54:48, 117.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 10000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 20000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 30000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 40000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 50000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 60000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 70000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 80000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 90000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 100000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 110000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 120000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 130000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 140000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 150000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 160000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 170000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 180000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 190000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 21/48 [39:48<52:49, 117.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 10000: Loss = 0.3752475082874298\n",
            "\n",
            "Validation loss: tensor(0.3724) \n",
            "\n",
            "Epoch 20000: Loss = 0.3426084518432617\n",
            "\n",
            "Validation loss: tensor(0.3314) \n",
            "\n",
            "Epoch 30000: Loss = 0.3212376832962036\n",
            "\n",
            "Validation loss: tensor(0.3000) \n",
            "\n",
            "Epoch 40000: Loss = 0.31018173694610596\n",
            "\n",
            "Validation loss: tensor(0.2997) \n",
            "\n",
            "Epoch 50000: Loss = 0.30879881978034973\n",
            "\n",
            "Validation loss: tensor(0.2954) \n",
            "\n",
            "Epoch 60000: Loss = 0.3084771931171417\n",
            "\n",
            "Validation loss: tensor(0.2971) \n",
            "\n",
            "Epoch 70000: Loss = 0.3083515465259552\n",
            "\n",
            "Validation loss: tensor(0.2976) \n",
            "\n",
            "Epoch 80000: Loss = 0.30823734402656555\n",
            "\n",
            "Validation loss: tensor(0.2972) \n",
            "\n",
            "Epoch 90000: Loss = 0.30806267261505127\n",
            "\n",
            "Validation loss: tensor(0.2964) \n",
            "\n",
            "Epoch 100000: Loss = 0.3079754114151001\n",
            "\n",
            "Validation loss: tensor(0.2956) \n",
            "\n",
            "Epoch 110000: Loss = 0.3079609274864197\n",
            "\n",
            "Validation loss: tensor(0.2958) \n",
            "\n",
            "Epoch 120000: Loss = 0.3079424202442169\n",
            "\n",
            "Validation loss: tensor(0.2957) \n",
            "\n",
            "Epoch 130000: Loss = 0.3079310655593872\n",
            "\n",
            "Validation loss: tensor(0.2957) \n",
            "\n",
            "Epoch 140000: Loss = 0.3079199492931366\n",
            "\n",
            "Validation loss: tensor(0.2955) \n",
            "\n",
            "Epoch 150000: Loss = 0.3079129457473755\n",
            "\n",
            "Validation loss: tensor(0.2955) \n",
            "\n",
            "Epoch 160000: Loss = 0.30790975689888\n",
            "\n",
            "Validation loss: tensor(0.2955) \n",
            "\n",
            "Epoch 170000: Loss = 0.30790331959724426\n",
            "\n",
            "Validation loss: tensor(0.2953) \n",
            "\n",
            "Epoch 180000: Loss = 0.3079017400741577\n",
            "\n",
            "Validation loss: tensor(0.2953) \n",
            "\n",
            "Epoch 190000: Loss = 0.30789896845817566\n",
            "\n",
            "Validation loss: tensor(0.2952) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 22/48 [41:24<48:06, 111.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.30789411067962646\n",
            "\n",
            "Validation loss: tensor(0.2950) \n",
            "\n",
            "Epoch 10000: Loss = 0.3079794943332672\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 20000: Loss = 0.30793723464012146\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 30000: Loss = 0.3079223930835724\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 40000: Loss = 0.30791690945625305\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 50000: Loss = 0.30791470408439636\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 60000: Loss = 0.3079133927822113\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 70000: Loss = 0.3079127371311188\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 80000: Loss = 0.30791234970092773\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 90000: Loss = 0.3079119622707367\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 100000: Loss = 0.3079116642475128\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 110000: Loss = 0.3079114854335785\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 120000: Loss = 0.3079115152359009\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 130000: Loss = 0.3079114556312561\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 140000: Loss = 0.3079114258289337\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 150000: Loss = 0.30791130661964417\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 160000: Loss = 0.30791136622428894\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 170000: Loss = 0.30791133642196655\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 180000: Loss = 0.30791130661964417\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 190000: Loss = 0.3079114258289337\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 23/48 [43:49<50:28, 121.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.30791130661964417\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 10000: Loss = 0.336010217666626\n",
            "\n",
            "Validation loss: tensor(0.3276) \n",
            "\n",
            "Epoch 20000: Loss = 0.3374214470386505\n",
            "\n",
            "Validation loss: tensor(0.2873) \n",
            "\n",
            "Epoch 30000: Loss = 0.31621870398521423\n",
            "\n",
            "Validation loss: tensor(0.2416) \n",
            "\n",
            "Epoch 40000: Loss = 0.16036327183246613\n",
            "\n",
            "Validation loss: tensor(0.1646) \n",
            "\n",
            "Epoch 50000: Loss = 0.14753612875938416\n",
            "\n",
            "Validation loss: tensor(0.1386) \n",
            "\n",
            "Epoch 60000: Loss = 0.07439848780632019\n",
            "\n",
            "Validation loss: tensor(0.1163) \n",
            "\n",
            "Epoch 70000: Loss = 0.10235735028982162\n",
            "\n",
            "Validation loss: tensor(0.1968) \n",
            "\n",
            "Epoch 80000: Loss = 0.03965653479099274\n",
            "\n",
            "Validation loss: tensor(0.0556) \n",
            "\n",
            "Epoch 90000: Loss = 0.02683313563466072\n",
            "\n",
            "Validation loss: tensor(0.0425) \n",
            "\n",
            "Epoch 100000: Loss = 0.032680444419384\n",
            "\n",
            "Validation loss: tensor(0.0660) \n",
            "\n",
            "Epoch 110000: Loss = 0.08565881848335266\n",
            "\n",
            "Validation loss: tensor(0.0501) \n",
            "\n",
            "Epoch 120000: Loss = 0.05856494605541229\n",
            "\n",
            "Validation loss: tensor(0.0667) \n",
            "\n",
            "Epoch 130000: Loss = 0.05219369754195213\n",
            "\n",
            "Validation loss: tensor(0.0507) \n",
            "\n",
            "Epoch 140000: Loss = 0.047451332211494446\n",
            "\n",
            "Validation loss: tensor(0.0537) \n",
            "\n",
            "Epoch 150000: Loss = 0.035934772342443466\n",
            "\n",
            "Validation loss: tensor(0.0451) \n",
            "\n",
            "Epoch 160000: Loss = 0.037704139947891235\n",
            "\n",
            "Validation loss: tensor(0.0465) \n",
            "\n",
            "Epoch 170000: Loss = 0.03363284096121788\n",
            "\n",
            "Validation loss: tensor(0.0440) \n",
            "\n",
            "Epoch 180000: Loss = 0.031451113522052765\n",
            "\n",
            "Validation loss: tensor(0.0408) \n",
            "\n",
            "Epoch 190000: Loss = 0.03724481910467148\n",
            "\n",
            "Validation loss: tensor(0.0440) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 24/48 [45:45<47:54, 119.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.03274333104491234\n",
            "\n",
            "Validation loss: tensor(0.0415) \n",
            "\n",
            "Epoch 10000: Loss = 0.3643333315849304\n",
            "\n",
            "Validation loss: tensor(0.3613) \n",
            "\n",
            "Epoch 20000: Loss = 0.3157128691673279\n",
            "\n",
            "Validation loss: tensor(0.3007) \n",
            "\n",
            "Epoch 30000: Loss = 0.16319423913955688\n",
            "\n",
            "Validation loss: tensor(0.1641) \n",
            "\n",
            "Epoch 40000: Loss = 0.05552869290113449\n",
            "\n",
            "Validation loss: tensor(0.0730) \n",
            "\n",
            "Epoch 50000: Loss = 0.045537468045949936\n",
            "\n",
            "Validation loss: tensor(0.0727) \n",
            "\n",
            "Epoch 60000: Loss = 0.045123565942049026\n",
            "\n",
            "Validation loss: tensor(0.0734) \n",
            "\n",
            "Epoch 70000: Loss = 0.04508562386035919\n",
            "\n",
            "Validation loss: tensor(0.0737) \n",
            "\n",
            "Epoch 80000: Loss = 0.045068465173244476\n",
            "\n",
            "Validation loss: tensor(0.0738) \n",
            "\n",
            "Epoch 90000: Loss = 0.04504929482936859\n",
            "\n",
            "Validation loss: tensor(0.0738) \n",
            "\n",
            "Epoch 100000: Loss = 0.045019183307886124\n",
            "\n",
            "Validation loss: tensor(0.0738) \n",
            "\n",
            "Epoch 110000: Loss = 0.044969357550144196\n",
            "\n",
            "Validation loss: tensor(0.0737) \n",
            "\n",
            "Epoch 120000: Loss = 0.04488622769713402\n",
            "\n",
            "Validation loss: tensor(0.0736) \n",
            "\n",
            "Epoch 130000: Loss = 0.04474501684308052\n",
            "\n",
            "Validation loss: tensor(0.0733) \n",
            "\n",
            "Epoch 140000: Loss = 0.04449902102351189\n",
            "\n",
            "Validation loss: tensor(0.0730) \n",
            "\n",
            "Epoch 150000: Loss = 0.04406826198101044\n",
            "\n",
            "Validation loss: tensor(0.0722) \n",
            "\n",
            "Epoch 160000: Loss = 0.043379753828048706\n",
            "\n",
            "Validation loss: tensor(0.0708) \n",
            "\n",
            "Epoch 170000: Loss = 0.04217007756233215\n",
            "\n",
            "Validation loss: tensor(0.0682) \n",
            "\n",
            "Epoch 180000: Loss = 0.04025152325630188\n",
            "\n",
            "Validation loss: tensor(0.0675) \n",
            "\n",
            "Epoch 190000: Loss = 0.03731182962656021\n",
            "\n",
            "Validation loss: tensor(0.0611) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 25/48 [47:38<45:08, 117.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.03331582993268967\n",
            "\n",
            "Validation loss: tensor(0.0549) \n",
            "\n",
            "Epoch 10000: Loss = 0.39678123593330383\n",
            "\n",
            "Validation loss: tensor(0.3968) \n",
            "\n",
            "Epoch 20000: Loss = 0.3956519067287445\n",
            "\n",
            "Validation loss: tensor(0.3973) \n",
            "\n",
            "Epoch 30000: Loss = 0.39556753635406494\n",
            "\n",
            "Validation loss: tensor(0.3974) \n",
            "\n",
            "Epoch 40000: Loss = 0.3954956829547882\n",
            "\n",
            "Validation loss: tensor(0.3973) \n",
            "\n",
            "Epoch 50000: Loss = 0.39541012048721313\n",
            "\n",
            "Validation loss: tensor(0.3972) \n",
            "\n",
            "Epoch 60000: Loss = 0.39532187581062317\n",
            "\n",
            "Validation loss: tensor(0.3971) \n",
            "\n",
            "Epoch 70000: Loss = 0.3952634334564209\n",
            "\n",
            "Validation loss: tensor(0.3970) \n",
            "\n",
            "Epoch 80000: Loss = 0.39521294832229614\n",
            "\n",
            "Validation loss: tensor(0.3969) \n",
            "\n",
            "Epoch 90000: Loss = 0.3951631486415863\n",
            "\n",
            "Validation loss: tensor(0.3969) \n",
            "\n",
            "Epoch 100000: Loss = 0.39511585235595703\n",
            "\n",
            "Validation loss: tensor(0.3968) \n",
            "\n",
            "Epoch 110000: Loss = 0.39506953954696655\n",
            "\n",
            "Validation loss: tensor(0.3967) \n",
            "\n",
            "Epoch 120000: Loss = 0.3950248956680298\n",
            "\n",
            "Validation loss: tensor(0.3966) \n",
            "\n",
            "Epoch 130000: Loss = 0.39498233795166016\n",
            "\n",
            "Validation loss: tensor(0.3965) \n",
            "\n",
            "Epoch 140000: Loss = 0.39494094252586365\n",
            "\n",
            "Validation loss: tensor(0.3965) \n",
            "\n",
            "Epoch 150000: Loss = 0.3949015736579895\n",
            "\n",
            "Validation loss: tensor(0.3964) \n",
            "\n",
            "Epoch 160000: Loss = 0.3948635160923004\n",
            "\n",
            "Validation loss: tensor(0.3964) \n",
            "\n",
            "Epoch 170000: Loss = 0.394827276468277\n",
            "\n",
            "Validation loss: tensor(0.3963) \n",
            "\n",
            "Epoch 180000: Loss = 0.39479270577430725\n",
            "\n",
            "Validation loss: tensor(0.3962) \n",
            "\n",
            "Epoch 190000: Loss = 0.39476004242897034\n",
            "\n",
            "Validation loss: tensor(0.3962) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 26/48 [49:15<40:53, 111.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.39472874999046326\n",
            "\n",
            "Validation loss: tensor(0.3961) \n",
            "\n",
            "Epoch 10000: Loss = 0.3408741354942322\n",
            "\n",
            "Validation loss: tensor(0.3368) \n",
            "\n",
            "Epoch 20000: Loss = 0.29419663548469543\n",
            "\n",
            "Validation loss: tensor(0.2841) \n",
            "\n",
            "Epoch 30000: Loss = 0.2063467651605606\n",
            "\n",
            "Validation loss: tensor(0.2026) \n",
            "\n",
            "Epoch 40000: Loss = 0.0632684975862503\n",
            "\n",
            "Validation loss: tensor(0.0860) \n",
            "\n",
            "Epoch 50000: Loss = 0.05985831841826439\n",
            "\n",
            "Validation loss: tensor(0.0853) \n",
            "\n",
            "Epoch 60000: Loss = 0.04257671535015106\n",
            "\n",
            "Validation loss: tensor(0.0700) \n",
            "\n",
            "Epoch 70000: Loss = 0.042223431169986725\n",
            "\n",
            "Validation loss: tensor(0.0698) \n",
            "\n",
            "Epoch 80000: Loss = 0.042175378650426865\n",
            "\n",
            "Validation loss: tensor(0.0698) \n",
            "\n",
            "Epoch 90000: Loss = 0.04215696454048157\n",
            "\n",
            "Validation loss: tensor(0.0696) \n",
            "\n",
            "Epoch 100000: Loss = 0.042146917432546616\n",
            "\n",
            "Validation loss: tensor(0.0697) \n",
            "\n",
            "Epoch 110000: Loss = 0.04214012250304222\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 120000: Loss = 0.0421355776488781\n",
            "\n",
            "Validation loss: tensor(0.0696) \n",
            "\n",
            "Epoch 130000: Loss = 0.042131852358579636\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 140000: Loss = 0.04212850704789162\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 150000: Loss = 0.042125459760427475\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 160000: Loss = 0.04212290793657303\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 170000: Loss = 0.04212042689323425\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 180000: Loss = 0.042111530900001526\n",
            "\n",
            "Validation loss: tensor(0.0694) \n",
            "\n",
            "Epoch 190000: Loss = 0.04210921376943588\n",
            "\n",
            "Validation loss: tensor(0.0694) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 27/48 [51:39<42:22, 121.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.042107176035642624\n",
            "\n",
            "Validation loss: tensor(0.0694) \n",
            "\n",
            "Epoch 10000: Loss = 0.39648178219795227\n",
            "\n",
            "Validation loss: tensor(0.3905) \n",
            "\n",
            "Epoch 20000: Loss = 0.3839469850063324\n",
            "\n",
            "Validation loss: tensor(0.3818) \n",
            "\n",
            "Epoch 30000: Loss = 0.379013329744339\n",
            "\n",
            "Validation loss: tensor(0.3773) \n",
            "\n",
            "Epoch 40000: Loss = 0.3741775155067444\n",
            "\n",
            "Validation loss: tensor(0.3724) \n",
            "\n",
            "Epoch 50000: Loss = 0.36855098605155945\n",
            "\n",
            "Validation loss: tensor(0.3664) \n",
            "\n",
            "Epoch 60000: Loss = 0.3625009059906006\n",
            "\n",
            "Validation loss: tensor(0.3596) \n",
            "\n",
            "Epoch 70000: Loss = 0.35602110624313354\n",
            "\n",
            "Validation loss: tensor(0.3514) \n",
            "\n",
            "Epoch 80000: Loss = 0.348739355802536\n",
            "\n",
            "Validation loss: tensor(0.3436) \n",
            "\n",
            "Epoch 90000: Loss = 0.3405406177043915\n",
            "\n",
            "Validation loss: tensor(0.3354) \n",
            "\n",
            "Epoch 100000: Loss = 0.3311837911605835\n",
            "\n",
            "Validation loss: tensor(0.3252) \n",
            "\n",
            "Epoch 110000: Loss = 0.31938841938972473\n",
            "\n",
            "Validation loss: tensor(0.3133) \n",
            "\n",
            "Epoch 120000: Loss = 0.3042910099029541\n",
            "\n",
            "Validation loss: tensor(0.2981) \n",
            "\n",
            "Epoch 130000: Loss = 0.2863616943359375\n",
            "\n",
            "Validation loss: tensor(0.2825) \n",
            "\n",
            "Epoch 140000: Loss = 0.26372483372688293\n",
            "\n",
            "Validation loss: tensor(0.2586) \n",
            "\n",
            "Epoch 150000: Loss = 0.23596502840518951\n",
            "\n",
            "Validation loss: tensor(0.2344) \n",
            "\n",
            "Epoch 160000: Loss = 0.2061893790960312\n",
            "\n",
            "Validation loss: tensor(0.2058) \n",
            "\n",
            "Epoch 170000: Loss = 0.1711609661579132\n",
            "\n",
            "Validation loss: tensor(0.1765) \n",
            "\n",
            "Epoch 180000: Loss = 0.14249905943870544\n",
            "\n",
            "Validation loss: tensor(0.1495) \n",
            "\n",
            "Epoch 190000: Loss = 0.12224667519330978\n",
            "\n",
            "Validation loss: tensor(0.1388) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 28/48 [53:38<40:11, 120.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.1106242835521698\n",
            "\n",
            "Validation loss: tensor(0.1460) \n",
            "\n",
            "Epoch 10000: Loss = 0.3968634009361267\n",
            "\n",
            "Validation loss: tensor(0.3967) \n",
            "\n",
            "Epoch 20000: Loss = 0.3955974876880646\n",
            "\n",
            "Validation loss: tensor(0.3972) \n",
            "\n",
            "Epoch 30000: Loss = 0.39551734924316406\n",
            "\n",
            "Validation loss: tensor(0.3973) \n",
            "\n",
            "Epoch 40000: Loss = 0.3954414427280426\n",
            "\n",
            "Validation loss: tensor(0.3972) \n",
            "\n",
            "Epoch 50000: Loss = 0.3953559100627899\n",
            "\n",
            "Validation loss: tensor(0.3971) \n",
            "\n",
            "Epoch 60000: Loss = 0.3952943682670593\n",
            "\n",
            "Validation loss: tensor(0.3970) \n",
            "\n",
            "Epoch 70000: Loss = 0.395246684551239\n",
            "\n",
            "Validation loss: tensor(0.3969) \n",
            "\n",
            "Epoch 80000: Loss = 0.3952001929283142\n",
            "\n",
            "Validation loss: tensor(0.3969) \n",
            "\n",
            "Epoch 90000: Loss = 0.3951549232006073\n",
            "\n",
            "Validation loss: tensor(0.3968) \n",
            "\n",
            "Epoch 100000: Loss = 0.3951109051704407\n",
            "\n",
            "Validation loss: tensor(0.3968) \n",
            "\n",
            "Epoch 110000: Loss = 0.3950684070587158\n",
            "\n",
            "Validation loss: tensor(0.3967) \n",
            "\n",
            "Epoch 120000: Loss = 0.3950270116329193\n",
            "\n",
            "Validation loss: tensor(0.3966) \n",
            "\n",
            "Epoch 130000: Loss = 0.3949870765209198\n",
            "\n",
            "Validation loss: tensor(0.3966) \n",
            "\n",
            "Epoch 140000: Loss = 0.39494845271110535\n",
            "\n",
            "Validation loss: tensor(0.3965) \n",
            "\n",
            "Epoch 150000: Loss = 0.39491117000579834\n",
            "\n",
            "Validation loss: tensor(0.3964) \n",
            "\n",
            "Epoch 160000: Loss = 0.3948756456375122\n",
            "\n",
            "Validation loss: tensor(0.3964) \n",
            "\n",
            "Epoch 170000: Loss = 0.39484143257141113\n",
            "\n",
            "Validation loss: tensor(0.3963) \n",
            "\n",
            "Epoch 180000: Loss = 0.3948081135749817\n",
            "\n",
            "Validation loss: tensor(0.3963) \n",
            "\n",
            "Epoch 190000: Loss = 0.3947773873806\n",
            "\n",
            "Validation loss: tensor(0.3962) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 29/48 [55:30<37:19, 117.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.3947472870349884\n",
            "\n",
            "Validation loss: tensor(0.3962) \n",
            "\n",
            "Epoch 10000: Loss = 0.44205242395401\n",
            "\n",
            "Validation loss: tensor(0.4284) \n",
            "\n",
            "Epoch 20000: Loss = 0.4256495237350464\n",
            "\n",
            "Validation loss: tensor(0.4156) \n",
            "\n",
            "Epoch 30000: Loss = 0.4149262309074402\n",
            "\n",
            "Validation loss: tensor(0.4077) \n",
            "\n",
            "Epoch 40000: Loss = 0.4079504907131195\n",
            "\n",
            "Validation loss: tensor(0.4028) \n",
            "\n",
            "Epoch 50000: Loss = 0.40345704555511475\n",
            "\n",
            "Validation loss: tensor(0.3999) \n",
            "\n",
            "Epoch 60000: Loss = 0.40058135986328125\n",
            "\n",
            "Validation loss: tensor(0.3983) \n",
            "\n",
            "Epoch 70000: Loss = 0.3987666964530945\n",
            "\n",
            "Validation loss: tensor(0.3974) \n",
            "\n",
            "Epoch 80000: Loss = 0.397621750831604\n",
            "\n",
            "Validation loss: tensor(0.3970) \n",
            "\n",
            "Epoch 90000: Loss = 0.39690232276916504\n",
            "\n",
            "Validation loss: tensor(0.3968) \n",
            "\n",
            "Epoch 100000: Loss = 0.3964519500732422\n",
            "\n",
            "Validation loss: tensor(0.3968) \n",
            "\n",
            "Epoch 110000: Loss = 0.39616477489471436\n",
            "\n",
            "Validation loss: tensor(0.3969) \n",
            "\n",
            "Epoch 120000: Loss = 0.3959854543209076\n",
            "\n",
            "Validation loss: tensor(0.3970) \n",
            "\n",
            "Epoch 130000: Loss = 0.3958711326122284\n",
            "\n",
            "Validation loss: tensor(0.3970) \n",
            "\n",
            "Epoch 140000: Loss = 0.3957943022251129\n",
            "\n",
            "Validation loss: tensor(0.3971) \n",
            "\n",
            "Epoch 150000: Loss = 0.3957407772541046\n",
            "\n",
            "Validation loss: tensor(0.3972) \n",
            "\n",
            "Epoch 160000: Loss = 0.39570122957229614\n",
            "\n",
            "Validation loss: tensor(0.3972) \n",
            "\n",
            "Epoch 170000: Loss = 0.3956644535064697\n",
            "\n",
            "Validation loss: tensor(0.3973) \n",
            "\n",
            "Epoch 180000: Loss = 0.3956339955329895\n",
            "\n",
            "Validation loss: tensor(0.3973) \n",
            "\n",
            "Epoch 190000: Loss = 0.39561885595321655\n",
            "\n",
            "Validation loss: tensor(0.3973) \n",
            "\n",
            "Epoch 200000: Loss = 0.39560988545417786\n",
            "\n",
            "Validation loss: tensor(0.3974) \n",
            "\n",
            "Epoch 10000: Loss = 0.39640164375305176\n",
            "\n",
            "Validation loss: tensor(0.3897) \n",
            "\n",
            "Epoch 20000: Loss = 0.38379576802253723\n",
            "\n",
            "Validation loss: tensor(0.3809) \n",
            "\n",
            "Epoch 30000: Loss = 0.37880203127861023\n",
            "\n",
            "Validation loss: tensor(0.3765) \n",
            "\n",
            "Epoch 40000: Loss = 0.37417125701904297\n",
            "\n",
            "Validation loss: tensor(0.3720) \n",
            "\n",
            "Epoch 50000: Loss = 0.3690702021121979\n",
            "\n",
            "Validation loss: tensor(0.3663) \n",
            "\n",
            "Epoch 60000: Loss = 0.3635825216770172\n",
            "\n",
            "Validation loss: tensor(0.3604) \n",
            "\n",
            "Epoch 70000: Loss = 0.3583468198776245\n",
            "\n",
            "Validation loss: tensor(0.3540) \n",
            "\n",
            "Epoch 80000: Loss = 0.3531040847301483\n",
            "\n",
            "Validation loss: tensor(0.3481) \n",
            "\n",
            "Epoch 90000: Loss = 0.34781622886657715\n",
            "\n",
            "Validation loss: tensor(0.3424) \n",
            "\n",
            "Epoch 100000: Loss = 0.34275367856025696\n",
            "\n",
            "Validation loss: tensor(0.3363) \n",
            "\n",
            "Epoch 110000: Loss = 0.3379441499710083\n",
            "\n",
            "Validation loss: tensor(0.3304) \n",
            "\n",
            "Epoch 120000: Loss = 0.3332877457141876\n",
            "\n",
            "Validation loss: tensor(0.3250) \n",
            "\n",
            "Epoch 130000: Loss = 0.3287481367588043\n",
            "\n",
            "Validation loss: tensor(0.3200) \n",
            "\n",
            "Epoch 140000: Loss = 0.3247607350349426\n",
            "\n",
            "Validation loss: tensor(0.3158) \n",
            "\n",
            "Epoch 150000: Loss = 0.32125377655029297\n",
            "\n",
            "Validation loss: tensor(0.3122) \n",
            "\n",
            "Epoch 160000: Loss = 0.31824997067451477\n",
            "\n",
            "Validation loss: tensor(0.3088) \n",
            "\n",
            "Epoch 170000: Loss = 0.31576454639434814\n",
            "\n",
            "Validation loss: tensor(0.3060) \n",
            "\n",
            "Epoch 180000: Loss = 0.3137694299221039\n",
            "\n",
            "Validation loss: tensor(0.3035) \n",
            "\n",
            "Epoch 190000: Loss = 0.31228402256965637\n",
            "\n",
            "Validation loss: tensor(0.3016) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 31/48 [59:24<33:49, 119.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.31120169162750244\n",
            "\n",
            "Validation loss: tensor(0.3000) \n",
            "\n",
            "Epoch 10000: Loss = 0.459043949842453\n",
            "\n",
            "Validation loss: tensor(0.4412) \n",
            "\n",
            "Epoch 20000: Loss = 0.446196585893631\n",
            "\n",
            "Validation loss: tensor(0.4305) \n",
            "\n",
            "Epoch 30000: Loss = 0.4362528920173645\n",
            "\n",
            "Validation loss: tensor(0.4224) \n",
            "\n",
            "Epoch 40000: Loss = 0.4279538094997406\n",
            "\n",
            "Validation loss: tensor(0.4159) \n",
            "\n",
            "Epoch 50000: Loss = 0.42098748683929443\n",
            "\n",
            "Validation loss: tensor(0.4102) \n",
            "\n",
            "Epoch 60000: Loss = 0.4121459722518921\n",
            "\n",
            "Validation loss: tensor(0.4023) \n",
            "\n",
            "Epoch 70000: Loss = 0.40721702575683594\n",
            "\n",
            "Validation loss: tensor(0.3983) \n",
            "\n",
            "Epoch 80000: Loss = 0.402525395154953\n",
            "\n",
            "Validation loss: tensor(0.3948) \n",
            "\n",
            "Epoch 90000: Loss = 0.3992483615875244\n",
            "\n",
            "Validation loss: tensor(0.3924) \n",
            "\n",
            "Epoch 100000: Loss = 0.39648932218551636\n",
            "\n",
            "Validation loss: tensor(0.3905) \n",
            "\n",
            "Epoch 110000: Loss = 0.3941902220249176\n",
            "\n",
            "Validation loss: tensor(0.3888) \n",
            "\n",
            "Epoch 120000: Loss = 0.3922623097896576\n",
            "\n",
            "Validation loss: tensor(0.3875) \n",
            "\n",
            "Epoch 130000: Loss = 0.3906407952308655\n",
            "\n",
            "Validation loss: tensor(0.3864) \n",
            "\n",
            "Epoch 140000: Loss = 0.389262855052948\n",
            "\n",
            "Validation loss: tensor(0.3854) \n",
            "\n",
            "Epoch 150000: Loss = 0.38807809352874756\n",
            "\n",
            "Validation loss: tensor(0.3846) \n",
            "\n",
            "Epoch 160000: Loss = 0.3870547413825989\n",
            "\n",
            "Validation loss: tensor(0.3840) \n",
            "\n",
            "Epoch 170000: Loss = 0.3861667215824127\n",
            "\n",
            "Validation loss: tensor(0.3834) \n",
            "\n",
            "Epoch 180000: Loss = 0.3853844106197357\n",
            "\n",
            "Validation loss: tensor(0.3828) \n",
            "\n",
            "Epoch 190000: Loss = 0.3846837878227234\n",
            "\n",
            "Validation loss: tensor(0.3823) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 32/48 [1:01:21<31:40, 118.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.38404586911201477\n",
            "\n",
            "Validation loss: tensor(0.3819) \n",
            "\n",
            "Epoch 10000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 20000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 30000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 40000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 50000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 60000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 70000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 80000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 90000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 100000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 110000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 120000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 130000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 140000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 150000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 160000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 170000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 180000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 190000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 33/48 [1:03:43<31:23, 125.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5151) \n",
            "\n",
            "Epoch 10000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 20000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 30000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 40000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 50000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 60000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 70000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 80000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 90000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 100000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 110000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 120000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 130000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 140000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 150000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 160000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 170000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 180000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 190000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 34/48 [1:05:29<27:56, 119.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5914) \n",
            "\n",
            "Epoch 10000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 20000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 30000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 40000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 50000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 60000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 70000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 80000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 90000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 100000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 110000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 120000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 130000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 140000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 150000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 160000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 170000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 180000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 190000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 35/48 [1:08:17<29:03, 134.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 10000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 20000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 30000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 40000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 50000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 60000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 70000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 80000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 90000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 100000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 110000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 120000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 130000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 140000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 150000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 160000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 170000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 180000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 190000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 36/48 [1:10:30<26:47, 133.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 10000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 20000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 30000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 40000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 50000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 60000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 70000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 80000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 90000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 100000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 110000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 120000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 130000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 140000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 150000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 160000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 170000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 180000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 190000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 37/48 [1:12:52<24:59, 136.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.48075032234191895\n",
            "\n",
            "Validation loss: tensor(0.5183) \n",
            "\n",
            "Epoch 10000: Loss = 0.3278105556964874\n",
            "\n",
            "Validation loss: tensor(0.3301) \n",
            "\n",
            "Epoch 20000: Loss = 0.19834178686141968\n",
            "\n",
            "Validation loss: tensor(0.2038) \n",
            "\n",
            "Epoch 30000: Loss = 0.14105311036109924\n",
            "\n",
            "Validation loss: tensor(0.1444) \n",
            "\n",
            "Epoch 40000: Loss = 0.11621429771184921\n",
            "\n",
            "Validation loss: tensor(0.1100) \n",
            "\n",
            "Epoch 50000: Loss = 0.09017160534858704\n",
            "\n",
            "Validation loss: tensor(0.1014) \n",
            "\n",
            "Epoch 60000: Loss = 0.12993305921554565\n",
            "\n",
            "Validation loss: tensor(0.0915) \n",
            "\n",
            "Epoch 70000: Loss = 0.07220940291881561\n",
            "\n",
            "Validation loss: tensor(0.0893) \n",
            "\n",
            "Epoch 80000: Loss = 0.12831644713878632\n",
            "\n",
            "Validation loss: tensor(0.1377) \n",
            "\n",
            "Epoch 90000: Loss = 0.11819819360971451\n",
            "\n",
            "Validation loss: tensor(0.6824) \n",
            "\n",
            "Epoch 100000: Loss = 0.06889895349740982\n",
            "\n",
            "Validation loss: tensor(2.5350) \n",
            "\n",
            "Epoch 110000: Loss = 0.047977495938539505\n",
            "\n",
            "Validation loss: tensor(5.4552) \n",
            "\n",
            "Epoch 120000: Loss = 0.04680221527814865\n",
            "\n",
            "Validation loss: tensor(8.3938) \n",
            "\n",
            "Epoch 130000: Loss = 0.05481909215450287\n",
            "\n",
            "Validation loss: tensor(14.5274) \n",
            "\n",
            "Epoch 140000: Loss = 0.05239609628915787\n",
            "\n",
            "Validation loss: tensor(20.6270) \n",
            "\n",
            "Epoch 150000: Loss = 0.047220584005117416\n",
            "\n",
            "Validation loss: tensor(25.8355) \n",
            "\n",
            "Epoch 160000: Loss = 0.04782024025917053\n",
            "\n",
            "Validation loss: tensor(28.5860) \n",
            "\n",
            "Epoch 170000: Loss = 0.04450222849845886\n",
            "\n",
            "Validation loss: tensor(29.4279) \n",
            "\n",
            "Epoch 180000: Loss = 0.04977033659815788\n",
            "\n",
            "Validation loss: tensor(29.9077) \n",
            "\n",
            "Epoch 190000: Loss = 0.04522275552153587\n",
            "\n",
            "Validation loss: tensor(30.3347) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 38/48 [1:14:37<21:10, 127.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.04494932293891907\n",
            "\n",
            "Validation loss: tensor(30.6072) \n",
            "\n",
            "Epoch 10000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 20000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 30000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 40000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 50000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 60000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 70000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 80000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 90000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 100000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 110000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 120000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 130000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 140000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 150000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 160000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 170000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 180000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 190000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 39/48 [1:17:25<20:51, 139.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = nan\n",
            "\n",
            "Validation loss: tensor(nan) \n",
            "\n",
            "Epoch 10000: Loss = 0.3101928234100342\n",
            "\n",
            "Validation loss: tensor(0.2964) \n",
            "\n",
            "Epoch 20000: Loss = 0.3083764314651489\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 30000: Loss = 0.3082129657268524\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 40000: Loss = 0.3081836998462677\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 50000: Loss = 0.3081715703010559\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 60000: Loss = 0.30816641449928284\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 70000: Loss = 0.30816391110420227\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 80000: Loss = 0.3081620931625366\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 90000: Loss = 0.30816081166267395\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 100000: Loss = 0.3081597089767456\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 110000: Loss = 0.3081587553024292\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 120000: Loss = 0.30815526843070984\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 130000: Loss = 0.30815383791923523\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 140000: Loss = 0.3081534504890442\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 150000: Loss = 0.30815306305885315\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 160000: Loss = 0.30815279483795166\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 170000: Loss = 0.30815255641937256\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 180000: Loss = 0.30815237760543823\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 190000: Loss = 0.3081522285938263\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 40/48 [1:19:40<18:23, 137.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.30815207958221436\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 10000: Loss = 0.3221571445465088\n",
            "\n",
            "Validation loss: tensor(0.3244) \n",
            "\n",
            "Epoch 20000: Loss = 0.31243860721588135\n",
            "\n",
            "Validation loss: tensor(0.2856) \n",
            "\n",
            "Epoch 30000: Loss = 0.308497816324234\n",
            "\n",
            "Validation loss: tensor(0.2945) \n",
            "\n",
            "Epoch 40000: Loss = 0.3088810443878174\n",
            "\n",
            "Validation loss: tensor(0.3022) \n",
            "\n",
            "Epoch 50000: Loss = 0.3080466687679291\n",
            "\n",
            "Validation loss: tensor(0.2937) \n",
            "\n",
            "Epoch 60000: Loss = 0.30799177289009094\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 70000: Loss = 0.30796852707862854\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 80000: Loss = 0.3079565763473511\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 90000: Loss = 0.30792877078056335\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 100000: Loss = 0.30791962146759033\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 110000: Loss = 0.30791187286376953\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 120000: Loss = 0.3079071044921875\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 130000: Loss = 0.3079041540622711\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 140000: Loss = 0.30790168046951294\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 150000: Loss = 0.30789902806282043\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 160000: Loss = 0.3078974783420563\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 170000: Loss = 0.30582237243652344\n",
            "\n",
            "Validation loss: tensor(0.2900) \n",
            "\n",
            "Epoch 180000: Loss = 0.30790674686431885\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 190000: Loss = 0.3079017400741577\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 41/48 [1:21:42<15:33, 133.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.307898610830307\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 10000: Loss = 0.3731319010257721\n",
            "\n",
            "Validation loss: tensor(0.3659) \n",
            "\n",
            "Epoch 20000: Loss = 0.35846030712127686\n",
            "\n",
            "Validation loss: tensor(0.3534) \n",
            "\n",
            "Epoch 30000: Loss = 0.350604772567749\n",
            "\n",
            "Validation loss: tensor(0.3451) \n",
            "\n",
            "Epoch 40000: Loss = 0.3423880636692047\n",
            "\n",
            "Validation loss: tensor(0.3362) \n",
            "\n",
            "Epoch 50000: Loss = 0.33310532569885254\n",
            "\n",
            "Validation loss: tensor(0.3263) \n",
            "\n",
            "Epoch 60000: Loss = 0.32350072264671326\n",
            "\n",
            "Validation loss: tensor(0.3152) \n",
            "\n",
            "Epoch 70000: Loss = 0.3118918538093567\n",
            "\n",
            "Validation loss: tensor(0.3032) \n",
            "\n",
            "Epoch 80000: Loss = 0.30378586053848267\n",
            "\n",
            "Validation loss: tensor(0.2931) \n",
            "\n",
            "Epoch 90000: Loss = 0.2951625883579254\n",
            "\n",
            "Validation loss: tensor(0.2829) \n",
            "\n",
            "Epoch 100000: Loss = 0.2873012125492096\n",
            "\n",
            "Validation loss: tensor(0.2710) \n",
            "\n",
            "Epoch 110000: Loss = 0.27611997723579407\n",
            "\n",
            "Validation loss: tensor(0.2611) \n",
            "\n",
            "Epoch 120000: Loss = 0.2696237862110138\n",
            "\n",
            "Validation loss: tensor(0.2504) \n",
            "\n",
            "Epoch 130000: Loss = 0.25924599170684814\n",
            "\n",
            "Validation loss: tensor(0.2370) \n",
            "\n",
            "Epoch 140000: Loss = 0.24938495457172394\n",
            "\n",
            "Validation loss: tensor(0.2238) \n",
            "\n",
            "Epoch 150000: Loss = 0.23944607377052307\n",
            "\n",
            "Validation loss: tensor(0.2095) \n",
            "\n",
            "Epoch 160000: Loss = 0.22331441938877106\n",
            "\n",
            "Validation loss: tensor(0.1931) \n",
            "\n",
            "Epoch 170000: Loss = 0.19394363462924957\n",
            "\n",
            "Validation loss: tensor(0.1640) \n",
            "\n",
            "Epoch 180000: Loss = 0.1737615019083023\n",
            "\n",
            "Validation loss: tensor(0.1434) \n",
            "\n",
            "Epoch 190000: Loss = 0.1590738445520401\n",
            "\n",
            "Validation loss: tensor(0.1278) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 42/48 [1:23:29<12:31, 125.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.14245270192623138\n",
            "\n",
            "Validation loss: tensor(0.1099) \n",
            "\n",
            "Epoch 10000: Loss = 0.32891204953193665\n",
            "\n",
            "Validation loss: tensor(0.3205) \n",
            "\n",
            "Epoch 20000: Loss = 0.30906403064727783\n",
            "\n",
            "Validation loss: tensor(0.2958) \n",
            "\n",
            "Epoch 30000: Loss = 0.3037349581718445\n",
            "\n",
            "Validation loss: tensor(0.2903) \n",
            "\n",
            "Epoch 40000: Loss = 0.08742162585258484\n",
            "\n",
            "Validation loss: tensor(0.1392) \n",
            "\n",
            "Epoch 50000: Loss = 0.03887995705008507\n",
            "\n",
            "Validation loss: tensor(0.0633) \n",
            "\n",
            "Epoch 60000: Loss = 0.041846390813589096\n",
            "\n",
            "Validation loss: tensor(0.0685) \n",
            "\n",
            "Epoch 70000: Loss = 0.043351203203201294\n",
            "\n",
            "Validation loss: tensor(0.0786) \n",
            "\n",
            "Epoch 80000: Loss = 0.04254832863807678\n",
            "\n",
            "Validation loss: tensor(0.0651) \n",
            "\n",
            "Epoch 90000: Loss = 0.041601572185754776\n",
            "\n",
            "Validation loss: tensor(0.0667) \n",
            "\n",
            "Epoch 100000: Loss = 0.04071182385087013\n",
            "\n",
            "Validation loss: tensor(0.0667) \n",
            "\n",
            "Epoch 110000: Loss = 0.0361221507191658\n",
            "\n",
            "Validation loss: tensor(0.0557) \n",
            "\n",
            "Epoch 120000: Loss = 0.0319390706717968\n",
            "\n",
            "Validation loss: tensor(0.0503) \n",
            "\n",
            "Epoch 130000: Loss = 0.021593814715743065\n",
            "\n",
            "Validation loss: tensor(0.0324) \n",
            "\n",
            "Epoch 140000: Loss = 0.012411167845129967\n",
            "\n",
            "Validation loss: tensor(0.0306) \n",
            "\n",
            "Epoch 150000: Loss = 0.0057581569999456406\n",
            "\n",
            "Validation loss: tensor(0.0113) \n",
            "\n",
            "Epoch 160000: Loss = 0.003137052757665515\n",
            "\n",
            "Validation loss: tensor(0.0072) \n",
            "\n",
            "Epoch 170000: Loss = 0.0018007653998211026\n",
            "\n",
            "Validation loss: tensor(0.0055) \n",
            "\n",
            "Epoch 180000: Loss = 0.0014359010383486748\n",
            "\n",
            "Validation loss: tensor(0.0043) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|████████▉ | 43/48 [1:26:03<11:10, 134.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.38481631875038147\n",
            "\n",
            "Validation loss: tensor(0.3827) \n",
            "\n",
            "Epoch 20000: Loss = 0.37715381383895874\n",
            "\n",
            "Validation loss: tensor(0.3747) \n",
            "\n",
            "Epoch 30000: Loss = 0.36756715178489685\n",
            "\n",
            "Validation loss: tensor(0.3648) \n",
            "\n",
            "Epoch 40000: Loss = 0.35500767827033997\n",
            "\n",
            "Validation loss: tensor(0.3509) \n",
            "\n",
            "Epoch 50000: Loss = 0.3490322232246399\n",
            "\n",
            "Validation loss: tensor(0.3220) \n",
            "\n",
            "Epoch 60000: Loss = 0.336536169052124\n",
            "\n",
            "Validation loss: tensor(0.3063) \n",
            "\n",
            "Epoch 70000: Loss = 0.3214358985424042\n",
            "\n",
            "Validation loss: tensor(0.2912) \n",
            "\n",
            "Epoch 80000: Loss = 0.3062572479248047\n",
            "\n",
            "Validation loss: tensor(0.2749) \n",
            "\n",
            "Epoch 90000: Loss = 0.28857430815696716\n",
            "\n",
            "Validation loss: tensor(0.2572) \n",
            "\n",
            "Epoch 100000: Loss = 0.2536589503288269\n",
            "\n",
            "Validation loss: tensor(0.2455) \n",
            "\n",
            "Epoch 110000: Loss = 0.22478540241718292\n",
            "\n",
            "Validation loss: tensor(0.2376) \n",
            "\n",
            "Epoch 120000: Loss = 0.19488142430782318\n",
            "\n",
            "Validation loss: tensor(0.2228) \n",
            "\n",
            "Epoch 130000: Loss = 0.17754913866519928\n",
            "\n",
            "Validation loss: tensor(0.2052) \n",
            "\n",
            "Epoch 140000: Loss = 0.1566966325044632\n",
            "\n",
            "Validation loss: tensor(0.1855) \n",
            "\n",
            "Epoch 150000: Loss = 0.14180611073970795\n",
            "\n",
            "Validation loss: tensor(0.1698) \n",
            "\n",
            "Epoch 160000: Loss = 0.13532964885234833\n",
            "\n",
            "Validation loss: tensor(0.1630) \n",
            "\n",
            "Epoch 170000: Loss = 0.1291983276605606\n",
            "\n",
            "Validation loss: tensor(0.1606) \n",
            "\n",
            "Epoch 180000: Loss = 0.12691597640514374\n",
            "\n",
            "Validation loss: tensor(0.1594) \n",
            "\n",
            "Epoch 190000: Loss = 0.09887389093637466\n",
            "\n",
            "Validation loss: tensor(0.1475) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 44/48 [1:28:19<08:57, 134.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.09050522744655609\n",
            "\n",
            "Validation loss: tensor(0.1397) \n",
            "\n",
            "Epoch 10000: Loss = 0.3790682256221771\n",
            "\n",
            "Validation loss: tensor(0.3759) \n",
            "\n",
            "Epoch 20000: Loss = 0.36816224455833435\n",
            "\n",
            "Validation loss: tensor(0.3633) \n",
            "\n",
            "Epoch 30000: Loss = 0.35763415694236755\n",
            "\n",
            "Validation loss: tensor(0.3500) \n",
            "\n",
            "Epoch 40000: Loss = 0.34898728132247925\n",
            "\n",
            "Validation loss: tensor(0.3397) \n",
            "\n",
            "Epoch 50000: Loss = 0.3417166471481323\n",
            "\n",
            "Validation loss: tensor(0.3312) \n",
            "\n",
            "Epoch 60000: Loss = 0.3357735574245453\n",
            "\n",
            "Validation loss: tensor(0.3250) \n",
            "\n",
            "Epoch 70000: Loss = 0.3303815722465515\n",
            "\n",
            "Validation loss: tensor(0.3201) \n",
            "\n",
            "Epoch 80000: Loss = 0.3255895674228668\n",
            "\n",
            "Validation loss: tensor(0.3156) \n",
            "\n",
            "Epoch 90000: Loss = 0.32161954045295715\n",
            "\n",
            "Validation loss: tensor(0.3117) \n",
            "\n",
            "Epoch 100000: Loss = 0.3183770477771759\n",
            "\n",
            "Validation loss: tensor(0.3085) \n",
            "\n",
            "Epoch 110000: Loss = 0.3157978951931\n",
            "\n",
            "Validation loss: tensor(0.3056) \n",
            "\n",
            "Epoch 120000: Loss = 0.31381621956825256\n",
            "\n",
            "Validation loss: tensor(0.3033) \n",
            "\n",
            "Epoch 130000: Loss = 0.3123481869697571\n",
            "\n",
            "Validation loss: tensor(0.3015) \n",
            "\n",
            "Epoch 140000: Loss = 0.3113153278827667\n",
            "\n",
            "Validation loss: tensor(0.3000) \n",
            "\n",
            "Epoch 150000: Loss = 0.3105986416339874\n",
            "\n",
            "Validation loss: tensor(0.2988) \n",
            "\n",
            "Epoch 160000: Loss = 0.3101225793361664\n",
            "\n",
            "Validation loss: tensor(0.2980) \n",
            "\n",
            "Epoch 170000: Loss = 0.3097551167011261\n",
            "\n",
            "Validation loss: tensor(0.2974) \n",
            "\n",
            "Epoch 180000: Loss = 0.30952218174934387\n",
            "\n",
            "Validation loss: tensor(0.2970) \n",
            "\n",
            "Epoch 190000: Loss = 0.30929356813430786\n",
            "\n",
            "Validation loss: tensor(0.2965) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 45/48 [1:30:20<06:31, 130.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.3091442286968231\n",
            "\n",
            "Validation loss: tensor(0.2961) \n",
            "\n",
            "Epoch 10000: Loss = 0.42124176025390625\n",
            "\n",
            "Validation loss: tensor(0.4086) \n",
            "\n",
            "Epoch 20000: Loss = 0.3968468904495239\n",
            "\n",
            "Validation loss: tensor(0.3897) \n",
            "\n",
            "Epoch 30000: Loss = 0.3896214962005615\n",
            "\n",
            "Validation loss: tensor(0.3847) \n",
            "\n",
            "Epoch 40000: Loss = 0.3861657977104187\n",
            "\n",
            "Validation loss: tensor(0.3825) \n",
            "\n",
            "Epoch 50000: Loss = 0.38438379764556885\n",
            "\n",
            "Validation loss: tensor(0.3813) \n",
            "\n",
            "Epoch 60000: Loss = 0.3831317126750946\n",
            "\n",
            "Validation loss: tensor(0.3803) \n",
            "\n",
            "Epoch 70000: Loss = 0.38205498456954956\n",
            "\n",
            "Validation loss: tensor(0.3793) \n",
            "\n",
            "Epoch 80000: Loss = 0.381035715341568\n",
            "\n",
            "Validation loss: tensor(0.3782) \n",
            "\n",
            "Epoch 90000: Loss = 0.38005271553993225\n",
            "\n",
            "Validation loss: tensor(0.3771) \n",
            "\n",
            "Epoch 100000: Loss = 0.3790756165981293\n",
            "\n",
            "Validation loss: tensor(0.3759) \n",
            "\n",
            "Epoch 110000: Loss = 0.37808310985565186\n",
            "\n",
            "Validation loss: tensor(0.3748) \n",
            "\n",
            "Epoch 120000: Loss = 0.37706664204597473\n",
            "\n",
            "Validation loss: tensor(0.3735) \n",
            "\n",
            "Epoch 130000: Loss = 0.3760294020175934\n",
            "\n",
            "Validation loss: tensor(0.3723) \n",
            "\n",
            "Epoch 140000: Loss = 0.374958872795105\n",
            "\n",
            "Validation loss: tensor(0.3710) \n",
            "\n",
            "Epoch 150000: Loss = 0.3738691210746765\n",
            "\n",
            "Validation loss: tensor(0.3698) \n",
            "\n",
            "Epoch 160000: Loss = 0.3727613687515259\n",
            "\n",
            "Validation loss: tensor(0.3686) \n",
            "\n",
            "Epoch 170000: Loss = 0.37161755561828613\n",
            "\n",
            "Validation loss: tensor(0.3673) \n",
            "\n",
            "Epoch 180000: Loss = 0.370466947555542\n",
            "\n",
            "Validation loss: tensor(0.3661) \n",
            "\n",
            "Epoch 190000: Loss = 0.36933791637420654\n",
            "\n",
            "Validation loss: tensor(0.3648) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 46/48 [1:32:06<04:06, 123.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.36821722984313965\n",
            "\n",
            "Validation loss: tensor(0.3634) \n",
            "\n",
            "Epoch 10000: Loss = 0.3863709568977356\n",
            "\n",
            "Validation loss: tensor(0.3846) \n",
            "\n",
            "Epoch 20000: Loss = 0.37977027893066406\n",
            "\n",
            "Validation loss: tensor(0.3780) \n",
            "\n",
            "Epoch 30000: Loss = 0.3719921112060547\n",
            "\n",
            "Validation loss: tensor(0.3692) \n",
            "\n",
            "Epoch 40000: Loss = 0.3620184063911438\n",
            "\n",
            "Validation loss: tensor(0.3586) \n",
            "\n",
            "Epoch 50000: Loss = 0.3506680428981781\n",
            "\n",
            "Validation loss: tensor(0.3456) \n",
            "\n",
            "Epoch 60000: Loss = 0.33821365237236023\n",
            "\n",
            "Validation loss: tensor(0.3323) \n",
            "\n",
            "Epoch 70000: Loss = 0.32355931401252747\n",
            "\n",
            "Validation loss: tensor(0.3176) \n",
            "\n",
            "Epoch 80000: Loss = 0.3068844676017761\n",
            "\n",
            "Validation loss: tensor(0.3007) \n",
            "\n",
            "Epoch 90000: Loss = 0.2854975759983063\n",
            "\n",
            "Validation loss: tensor(0.2803) \n",
            "\n",
            "Epoch 100000: Loss = 0.25668108463287354\n",
            "\n",
            "Validation loss: tensor(0.2541) \n",
            "\n",
            "Epoch 110000: Loss = 0.21886537969112396\n",
            "\n",
            "Validation loss: tensor(0.2194) \n",
            "\n",
            "Epoch 120000: Loss = 0.1743495911359787\n",
            "\n",
            "Validation loss: tensor(0.1796) \n",
            "\n",
            "Epoch 130000: Loss = 0.13062512874603271\n",
            "\n",
            "Validation loss: tensor(0.1382) \n",
            "\n",
            "Epoch 140000: Loss = 0.0932660698890686\n",
            "\n",
            "Validation loss: tensor(0.1052) \n",
            "\n",
            "Epoch 150000: Loss = 0.06662953644990921\n",
            "\n",
            "Validation loss: tensor(0.0847) \n",
            "\n",
            "Epoch 160000: Loss = 0.05285685509443283\n",
            "\n",
            "Validation loss: tensor(0.0749) \n",
            "\n",
            "Epoch 170000: Loss = 0.04734024405479431\n",
            "\n",
            "Validation loss: tensor(0.0716) \n",
            "\n",
            "Epoch 180000: Loss = 0.04499609023332596\n",
            "\n",
            "Validation loss: tensor(0.0704) \n",
            "\n",
            "Epoch 190000: Loss = 0.04381554201245308\n",
            "\n",
            "Validation loss: tensor(0.0699) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 47/48 [1:34:44<02:13, 133.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.04315507411956787\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 10000: Loss = 0.43857288360595703\n",
            "\n",
            "Validation loss: tensor(0.4240) \n",
            "\n",
            "Epoch 20000: Loss = 0.4201413691043854\n",
            "\n",
            "Validation loss: tensor(0.4088) \n",
            "\n",
            "Epoch 30000: Loss = 0.4070691764354706\n",
            "\n",
            "Validation loss: tensor(0.3984) \n",
            "\n",
            "Epoch 40000: Loss = 0.39942505955696106\n",
            "\n",
            "Validation loss: tensor(0.3928) \n",
            "\n",
            "Epoch 50000: Loss = 0.3938693106174469\n",
            "\n",
            "Validation loss: tensor(0.3889) \n",
            "\n",
            "Epoch 60000: Loss = 0.39065486192703247\n",
            "\n",
            "Validation loss: tensor(0.3868) \n",
            "\n",
            "Epoch 70000: Loss = 0.38850080966949463\n",
            "\n",
            "Validation loss: tensor(0.3854) \n",
            "\n",
            "Epoch 80000: Loss = 0.3869899809360504\n",
            "\n",
            "Validation loss: tensor(0.3844) \n",
            "\n",
            "Epoch 90000: Loss = 0.38585054874420166\n",
            "\n",
            "Validation loss: tensor(0.3837) \n",
            "\n",
            "Epoch 100000: Loss = 0.3849305212497711\n",
            "\n",
            "Validation loss: tensor(0.3830) \n",
            "\n",
            "Epoch 110000: Loss = 0.38412708044052124\n",
            "\n",
            "Validation loss: tensor(0.3823) \n",
            "\n",
            "Epoch 120000: Loss = 0.3833826184272766\n",
            "\n",
            "Validation loss: tensor(0.3817) \n",
            "\n",
            "Epoch 130000: Loss = 0.3826580047607422\n",
            "\n",
            "Validation loss: tensor(0.3810) \n",
            "\n",
            "Epoch 140000: Loss = 0.3819371461868286\n",
            "\n",
            "Validation loss: tensor(0.3802) \n",
            "\n",
            "Epoch 150000: Loss = 0.38122105598449707\n",
            "\n",
            "Validation loss: tensor(0.3795) \n",
            "\n",
            "Epoch 160000: Loss = 0.3804929852485657\n",
            "\n",
            "Validation loss: tensor(0.3787) \n",
            "\n",
            "Epoch 170000: Loss = 0.3797481954097748\n",
            "\n",
            "Validation loss: tensor(0.3778) \n",
            "\n",
            "Epoch 180000: Loss = 0.3789834678173065\n",
            "\n",
            "Validation loss: tensor(0.3770) \n",
            "\n",
            "Epoch 190000: Loss = 0.3782013952732086\n",
            "\n",
            "Validation loss: tensor(0.3761) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 48/48 [1:36:59<00:00, 121.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.37739548087120056\n",
            "\n",
            "Validation loss: tensor(0.3751) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# loop for possible hyperparameter combinations with SGD optimizer\n",
        "\n",
        "# iterates over possible combinations of hidden size, learning rate, number of hidden layers and momentum\n",
        "\n",
        "for hsize, lr, num_hidden_lay, momentum in tqdm(hparam_list_sgd):\n",
        "    seed = 42\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    model, criterion, optimizer = create_net_loss_optim(hsize, num_hidden_lay, \"sgd\", lr, momentum)\n",
        "    losses, vallosses, epoch, _ = _train(x_train, y_train, criterion, optimizer, model)\n",
        "\n",
        "    results.append(\n",
        "        {\n",
        "            \"num_hidden_layer\": num_hidden_lay,\n",
        "            \"hiddensize\": hsize,\n",
        "            \"lr\": lr,\n",
        "            \"optimizer\": \"SGD\",\n",
        "            \"momentum\": momentum,\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": losses,\n",
        "            \"val_loss\": vallosses,\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBNdxc77r8qd"
      },
      "source": [
        "#### adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrd9qfPuslfg",
        "outputId": "e61705e1-48e3-4ec4-8e7c-6ee3b85d0fca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 0.01, 1)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hparam_list_adam[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4tVvaIgrnft",
        "outputId": "d1e0e612-8424-4ce7-a9df-664c07f1c6a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/24 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.30952340364456177\n",
            "\n",
            "Validation loss: tensor(0.2958) \n",
            "\n",
            "Epoch 20000: Loss = 0.30816709995269775\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 30000: Loss = 0.30815210938453674\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 40000: Loss = 0.3081493079662323\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 50000: Loss = 0.3083201050758362\n",
            "\n",
            "Validation loss: tensor(0.2936) \n",
            "\n",
            "Epoch 60000: Loss = 0.30815011262893677\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 70000: Loss = 0.30815011262893677\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 80000: Loss = 0.30815011262893677\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 90000: Loss = 0.30815011262893677\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 100000: Loss = 0.30815017223358154\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 110000: Loss = 0.3081500828266144\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 120000: Loss = 0.3081500828266144\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 130000: Loss = 0.30814942717552185\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 140000: Loss = 0.30814942717552185\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 150000: Loss = 0.30822139978408813\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 160000: Loss = 0.30822259187698364\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 170000: Loss = 0.30822134017944336\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 180000: Loss = 0.30822131037712097\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 190000: Loss = 0.3082215189933777\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 1/24 [02:48<1:04:30, 168.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.30822136998176575\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 10000: Loss = 0.049484752118587494\n",
            "\n",
            "Validation loss: tensor(0.1002) \n",
            "\n",
            "Epoch 20000: Loss = 0.05467982590198517\n",
            "\n",
            "Validation loss: tensor(0.0814) \n",
            "\n",
            "Epoch 30000: Loss = 0.014257916249334812\n",
            "\n",
            "Validation loss: tensor(0.0237) \n",
            "\n",
            "Epoch 40000: Loss = 0.01339843962341547\n",
            "\n",
            "Validation loss: tensor(0.0218) \n",
            "\n",
            "Epoch 50000: Loss = 0.013545925728976727\n",
            "\n",
            "Validation loss: tensor(0.0222) \n",
            "\n",
            "Epoch 60000: Loss = 0.013342912308871746\n",
            "\n",
            "Validation loss: tensor(0.0216) \n",
            "\n",
            "Epoch 70000: Loss = 0.013346067629754543\n",
            "\n",
            "Validation loss: tensor(0.0216) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 2/24 [04:03<41:41, 113.69s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.30910515785217285\n",
            "\n",
            "Validation loss: tensor(0.2940) \n",
            "\n",
            "Epoch 20000: Loss = 0.30804434418678284\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 30000: Loss = 0.3078882396221161\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 40000: Loss = 0.3078874945640564\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 50000: Loss = 0.30788490176200867\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 60000: Loss = 0.04505009576678276\n",
            "\n",
            "Validation loss: tensor(0.0720) \n",
            "\n",
            "Epoch 70000: Loss = 0.04504392668604851\n",
            "\n",
            "Validation loss: tensor(0.0720) \n",
            "\n",
            "Epoch 80000: Loss = 0.07284709066152573\n",
            "\n",
            "Validation loss: tensor(0.0811) \n",
            "\n",
            "Epoch 90000: Loss = 0.04505277797579765\n",
            "\n",
            "Validation loss: tensor(0.0716) \n",
            "\n",
            "Epoch 100000: Loss = 0.014491512440145016\n",
            "\n",
            "Validation loss: tensor(0.0253) \n",
            "\n",
            "Epoch 110000: Loss = 0.006063586566597223\n",
            "\n",
            "Validation loss: tensor(0.0127) \n",
            "\n",
            "Epoch 120000: Loss = 0.004481730051338673\n",
            "\n",
            "Validation loss: tensor(0.0096) \n",
            "\n",
            "Epoch 130000: Loss = 0.004049774259328842\n",
            "\n",
            "Validation loss: tensor(0.0083) \n",
            "\n",
            "Epoch 140000: Loss = 0.003933261148631573\n",
            "\n",
            "Validation loss: tensor(0.0081) \n",
            "\n",
            "Epoch 150000: Loss = 0.003944536671042442\n",
            "\n",
            "Validation loss: tensor(0.0082) \n",
            "\n",
            "Epoch 160000: Loss = 0.003885992569848895\n",
            "\n",
            "Validation loss: tensor(0.0080) \n",
            "\n",
            "Epoch 170000: Loss = 0.005272809416055679\n",
            "\n",
            "Validation loss: tensor(0.0081) \n",
            "\n",
            "Epoch 180000: Loss = 0.0028321000281721354\n",
            "\n",
            "Validation loss: tensor(0.0094) \n",
            "\n",
            "Epoch 190000: Loss = 0.005454906262457371\n",
            "\n",
            "Validation loss: tensor(0.0085) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 3/24 [06:48<48:00, 137.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.001986009068787098\n",
            "\n",
            "Validation loss: tensor(0.0054) \n",
            "\n",
            "Epoch 10000: Loss = 0.0068016271106898785\n",
            "\n",
            "Validation loss: tensor(0.0145) \n",
            "\n",
            "Epoch 20000: Loss = 0.003122917376458645\n",
            "\n",
            "Validation loss: tensor(0.0074) \n",
            "\n",
            "Epoch 30000: Loss = 0.001803533872589469\n",
            "\n",
            "Validation loss: tensor(0.0051) \n",
            "\n",
            "Epoch 40000: Loss = 0.002001154003664851\n",
            "\n",
            "Validation loss: tensor(0.0041) \n",
            "\n",
            "Epoch 50000: Loss = 0.0013623695122078061\n",
            "\n",
            "Validation loss: tensor(0.0033) \n",
            "\n",
            "Epoch 60000: Loss = 0.0014195962576195598\n",
            "\n",
            "Validation loss: tensor(0.0038) \n",
            "\n",
            "Epoch 70000: Loss = 0.001444778754375875\n",
            "\n",
            "Validation loss: tensor(0.0038) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 4/24 [08:05<37:43, 113.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.13888204097747803\n",
            "\n",
            "Validation loss: tensor(0.1478) \n",
            "\n",
            "Epoch 20000: Loss = 0.04343307390809059\n",
            "\n",
            "Validation loss: tensor(0.0779) \n",
            "\n",
            "Epoch 30000: Loss = 0.03988219425082207\n",
            "\n",
            "Validation loss: tensor(0.0758) \n",
            "\n",
            "Epoch 40000: Loss = 0.017264585942029953\n",
            "\n",
            "Validation loss: tensor(0.0410) \n",
            "\n",
            "Epoch 50000: Loss = 0.0023641616571694613\n",
            "\n",
            "Validation loss: tensor(0.0130) \n",
            "\n",
            "Epoch 60000: Loss = 0.0013297077966853976\n",
            "\n",
            "Validation loss: tensor(0.0103) \n",
            "\n",
            "Epoch 70000: Loss = 0.0013788542710244656\n",
            "\n",
            "Validation loss: tensor(0.0103) \n",
            "\n",
            "Epoch 80000: Loss = 0.0020935344509780407\n",
            "\n",
            "Validation loss: tensor(0.0111) \n",
            "\n",
            "Epoch 90000: Loss = 0.00132773129735142\n",
            "\n",
            "Validation loss: tensor(0.0102) \n",
            "\n",
            "Epoch 100000: Loss = 0.0013231931952759624\n",
            "\n",
            "Validation loss: tensor(0.0102) \n",
            "\n",
            "Epoch 110000: Loss = 0.0013229931937530637\n",
            "\n",
            "Validation loss: tensor(0.0101) \n",
            "\n",
            "Epoch 120000: Loss = 0.0013401294127106667\n",
            "\n",
            "Validation loss: tensor(0.0101) \n",
            "\n",
            "Epoch 130000: Loss = 0.0013681448763236403\n",
            "\n",
            "Validation loss: tensor(0.0103) \n",
            "\n",
            "Epoch 140000: Loss = 0.0013207191368564963\n",
            "\n",
            "Validation loss: tensor(0.0101) \n",
            "\n",
            "Epoch 150000: Loss = 0.0013188784942030907\n",
            "\n",
            "Validation loss: tensor(0.0101) \n",
            "\n",
            "Epoch 160000: Loss = 0.0013296791585162282\n",
            "\n",
            "Validation loss: tensor(0.0101) \n",
            "\n",
            "Epoch 170000: Loss = 0.0013494293671101332\n",
            "\n",
            "Validation loss: tensor(0.0101) \n",
            "\n",
            "Epoch 180000: Loss = 0.0013171297032386065\n",
            "\n",
            "Validation loss: tensor(0.0100) \n",
            "\n",
            "Epoch 190000: Loss = 0.0013310411013662815\n",
            "\n",
            "Validation loss: tensor(0.0100) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 5/24 [10:49<41:43, 131.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.0013161960523575544\n",
            "\n",
            "Validation loss: tensor(0.0100) \n",
            "\n",
            "Epoch 10000: Loss = 0.02004593051970005\n",
            "\n",
            "Validation loss: tensor(0.0326) \n",
            "\n",
            "Epoch 20000: Loss = 0.0011724770301952958\n",
            "\n",
            "Validation loss: tensor(0.0043) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 6/24 [11:11<28:19, 94.42s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.3749963045120239\n",
            "\n",
            "Validation loss: tensor(0.3739) \n",
            "\n",
            "Epoch 20000: Loss = 0.35313934087753296\n",
            "\n",
            "Validation loss: tensor(0.3470) \n",
            "\n",
            "Epoch 30000: Loss = 0.33593645691871643\n",
            "\n",
            "Validation loss: tensor(0.3258) \n",
            "\n",
            "Epoch 40000: Loss = 0.2986167073249817\n",
            "\n",
            "Validation loss: tensor(0.2925) \n",
            "\n",
            "Epoch 50000: Loss = 0.27230313420295715\n",
            "\n",
            "Validation loss: tensor(0.2663) \n",
            "\n",
            "Epoch 60000: Loss = 0.23876157402992249\n",
            "\n",
            "Validation loss: tensor(0.2361) \n",
            "\n",
            "Epoch 70000: Loss = 0.20443911850452423\n",
            "\n",
            "Validation loss: tensor(0.2066) \n",
            "\n",
            "Epoch 80000: Loss = 0.16323639452457428\n",
            "\n",
            "Validation loss: tensor(0.1705) \n",
            "\n",
            "Epoch 90000: Loss = 0.11921561509370804\n",
            "\n",
            "Validation loss: tensor(0.1296) \n",
            "\n",
            "Epoch 100000: Loss = 0.08440494537353516\n",
            "\n",
            "Validation loss: tensor(0.0978) \n",
            "\n",
            "Epoch 110000: Loss = 0.05507226288318634\n",
            "\n",
            "Validation loss: tensor(0.0771) \n",
            "\n",
            "Epoch 120000: Loss = 0.04498620331287384\n",
            "\n",
            "Validation loss: tensor(0.0728) \n",
            "\n",
            "Epoch 130000: Loss = 0.042903438210487366\n",
            "\n",
            "Validation loss: tensor(0.0738) \n",
            "\n",
            "Epoch 140000: Loss = 0.04279981553554535\n",
            "\n",
            "Validation loss: tensor(0.0734) \n",
            "\n",
            "Epoch 150000: Loss = 0.04273433983325958\n",
            "\n",
            "Validation loss: tensor(0.0733) \n",
            "\n",
            "Epoch 160000: Loss = 0.04268541932106018\n",
            "\n",
            "Validation loss: tensor(0.0731) \n",
            "\n",
            "Epoch 170000: Loss = 0.0426509752869606\n",
            "\n",
            "Validation loss: tensor(0.0729) \n",
            "\n",
            "Epoch 180000: Loss = 0.04262900352478027\n",
            "\n",
            "Validation loss: tensor(0.0729) \n",
            "\n",
            "Epoch 190000: Loss = 0.04261563718318939\n",
            "\n",
            "Validation loss: tensor(0.0728) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 7/24 [13:55<33:08, 116.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.04260849952697754\n",
            "\n",
            "Validation loss: tensor(0.0727) \n",
            "\n",
            "Epoch 10000: Loss = 0.3837672770023346\n",
            "\n",
            "Validation loss: tensor(0.3829) \n",
            "\n",
            "Epoch 20000: Loss = 0.34782707691192627\n",
            "\n",
            "Validation loss: tensor(0.3425) \n",
            "\n",
            "Epoch 30000: Loss = 0.2705397307872772\n",
            "\n",
            "Validation loss: tensor(0.2676) \n",
            "\n",
            "Epoch 40000: Loss = 0.1386888325214386\n",
            "\n",
            "Validation loss: tensor(0.1491) \n",
            "\n",
            "Epoch 50000: Loss = 0.05064982920885086\n",
            "\n",
            "Validation loss: tensor(0.0750) \n",
            "\n",
            "Epoch 60000: Loss = 0.04500444978475571\n",
            "\n",
            "Validation loss: tensor(0.0733) \n",
            "\n",
            "Epoch 70000: Loss = 0.04500430449843407\n",
            "\n",
            "Validation loss: tensor(0.0733) \n",
            "\n",
            "Epoch 80000: Loss = 0.0450044684112072\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 90000: Loss = 0.0450044684112072\n",
            "\n",
            "Validation loss: tensor(0.0733) \n",
            "\n",
            "Epoch 100000: Loss = 0.04500440135598183\n",
            "\n",
            "Validation loss: tensor(0.0733) \n",
            "\n",
            "Epoch 110000: Loss = 0.04500436410307884\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 120000: Loss = 0.045004285871982574\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 130000: Loss = 0.04500431567430496\n",
            "\n",
            "Validation loss: tensor(0.0733) \n",
            "\n",
            "Epoch 140000: Loss = 0.04500441253185272\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 150000: Loss = 0.04500419646501541\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 160000: Loss = 0.045004505664110184\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 170000: Loss = 0.04500437155365944\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 180000: Loss = 0.045004282146692276\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 190000: Loss = 0.045004237443208694\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 8/24 [17:19<38:36, 144.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.04500434547662735\n",
            "\n",
            "Validation loss: tensor(0.0732) \n",
            "\n",
            "Epoch 10000: Loss = 0.0570562370121479\n",
            "\n",
            "Validation loss: tensor(0.0678) \n",
            "\n",
            "Epoch 20000: Loss = 0.045004792511463165\n",
            "\n",
            "Validation loss: tensor(0.0722) \n",
            "\n",
            "Epoch 30000: Loss = 0.042872052639722824\n",
            "\n",
            "Validation loss: tensor(0.0677) \n",
            "\n",
            "Epoch 40000: Loss = 0.04220081493258476\n",
            "\n",
            "Validation loss: tensor(0.0694) \n",
            "\n",
            "Epoch 50000: Loss = 0.042047370225191116\n",
            "\n",
            "Validation loss: tensor(0.0678) \n",
            "\n",
            "Epoch 60000: Loss = 0.04207476228475571\n",
            "\n",
            "Validation loss: tensor(0.0682) \n",
            "\n",
            "Epoch 70000: Loss = 0.04207128658890724\n",
            "\n",
            "Validation loss: tensor(0.0682) \n",
            "\n",
            "Epoch 80000: Loss = 0.042072221636772156\n",
            "\n",
            "Validation loss: tensor(0.0681) \n",
            "\n",
            "Epoch 90000: Loss = 0.042071472853422165\n",
            "\n",
            "Validation loss: tensor(0.0681) \n",
            "\n",
            "Epoch 100000: Loss = 0.0420713946223259\n",
            "\n",
            "Validation loss: tensor(0.0682) \n",
            "\n",
            "Epoch 110000: Loss = 0.04207135736942291\n",
            "\n",
            "Validation loss: tensor(0.0682) \n",
            "\n",
            "Epoch 120000: Loss = 0.04211398959159851\n",
            "\n",
            "Validation loss: tensor(0.0816) \n",
            "\n",
            "Epoch 130000: Loss = 0.04207143187522888\n",
            "\n",
            "Validation loss: tensor(0.0825) \n",
            "\n",
            "Epoch 140000: Loss = 0.04212331771850586\n",
            "\n",
            "Validation loss: tensor(0.0794) \n",
            "\n",
            "Epoch 150000: Loss = 0.042127300053834915\n",
            "\n",
            "Validation loss: tensor(0.0766) \n",
            "\n",
            "Epoch 160000: Loss = 0.04207289218902588\n",
            "\n",
            "Validation loss: tensor(0.0717) \n",
            "\n",
            "Epoch 170000: Loss = 0.042071547359228134\n",
            "\n",
            "Validation loss: tensor(0.0693) \n",
            "\n",
            "Epoch 180000: Loss = 0.04207143932580948\n",
            "\n",
            "Validation loss: tensor(0.0684) \n",
            "\n",
            "Epoch 190000: Loss = 0.0420798696577549\n",
            "\n",
            "Validation loss: tensor(0.0687) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 9/24 [20:23<39:16, 157.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.04207167774438858\n",
            "\n",
            "Validation loss: tensor(0.0684) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 10/24 [20:32<25:56, 111.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.30789732933044434\n",
            "\n",
            "Validation loss: tensor(0.2935) \n",
            "\n",
            "Epoch 20000: Loss = 0.04424602910876274\n",
            "\n",
            "Validation loss: tensor(0.0687) \n",
            "\n",
            "Epoch 30000: Loss = 0.016944771632552147\n",
            "\n",
            "Validation loss: tensor(0.0245) \n",
            "\n",
            "Epoch 40000: Loss = 0.0037315732333809137\n",
            "\n",
            "Validation loss: tensor(0.0097) \n",
            "\n",
            "Epoch 50000: Loss = 0.0041310773231089115\n",
            "\n",
            "Validation loss: tensor(0.0111) \n",
            "\n",
            "Epoch 60000: Loss = 0.0012557239970192313\n",
            "\n",
            "Validation loss: tensor(0.0044) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 11/24 [21:32<20:44, 95.71s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70000: Loss = 0.0383906252682209\n",
            "\n",
            "Validation loss: tensor(0.0445) \n",
            "\n",
            "Epoch 10000: Loss = 0.3079068064689636\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 20000: Loss = 0.017645638436079025\n",
            "\n",
            "Validation loss: tensor(0.0256) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 12/24 [21:59<14:57, 74.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.3079186975955963\n",
            "\n",
            "Validation loss: tensor(0.2937) \n",
            "\n",
            "Epoch 20000: Loss = 0.30788806080818176\n",
            "\n",
            "Validation loss: tensor(0.2939) \n",
            "\n",
            "Epoch 30000: Loss = 0.3078869581222534\n",
            "\n",
            "Validation loss: tensor(0.2939) \n",
            "\n",
            "Epoch 40000: Loss = 0.30788469314575195\n",
            "\n",
            "Validation loss: tensor(0.2938) \n",
            "\n",
            "Epoch 50000: Loss = 0.3078839182853699\n",
            "\n",
            "Validation loss: tensor(0.2939) \n",
            "\n",
            "Epoch 60000: Loss = 0.30788326263427734\n",
            "\n",
            "Validation loss: tensor(0.2937) \n",
            "\n",
            "Epoch 70000: Loss = 0.30788230895996094\n",
            "\n",
            "Validation loss: tensor(0.2939) \n",
            "\n",
            "Epoch 80000: Loss = 0.30788177251815796\n",
            "\n",
            "Validation loss: tensor(0.2939) \n",
            "\n",
            "Epoch 90000: Loss = 0.30788111686706543\n",
            "\n",
            "Validation loss: tensor(0.2938) \n",
            "\n",
            "Epoch 100000: Loss = 0.30788087844848633\n",
            "\n",
            "Validation loss: tensor(0.2938) \n",
            "\n",
            "Epoch 110000: Loss = 0.3078804612159729\n",
            "\n",
            "Validation loss: tensor(0.2939) \n",
            "\n",
            "Epoch 120000: Loss = 0.3078804016113281\n",
            "\n",
            "Validation loss: tensor(0.2939) \n",
            "\n",
            "Epoch 130000: Loss = 0.22373303771018982\n",
            "\n",
            "Validation loss: tensor(0.2215) \n",
            "\n",
            "Epoch 140000: Loss = 0.0450076162815094\n",
            "\n",
            "Validation loss: tensor(0.0729) \n",
            "\n",
            "Epoch 150000: Loss = 0.04500468075275421\n",
            "\n",
            "Validation loss: tensor(0.0730) \n",
            "\n",
            "Epoch 160000: Loss = 0.04500437155365944\n",
            "\n",
            "Validation loss: tensor(0.0730) \n",
            "\n",
            "Epoch 170000: Loss = 0.045004259794950485\n",
            "\n",
            "Validation loss: tensor(0.0730) \n",
            "\n",
            "Epoch 180000: Loss = 0.0450044721364975\n",
            "\n",
            "Validation loss: tensor(0.0729) \n",
            "\n",
            "Epoch 190000: Loss = 0.045004043728113174\n",
            "\n",
            "Validation loss: tensor(0.0729) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 13/24 [24:52<19:09, 104.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.045004379004240036\n",
            "\n",
            "Validation loss: tensor(0.0729) \n",
            "\n",
            "Epoch 10000: Loss = 0.02672438696026802\n",
            "\n",
            "Validation loss: tensor(0.0420) \n",
            "\n",
            "Epoch 20000: Loss = 0.008897185325622559\n",
            "\n",
            "Validation loss: tensor(0.0170) \n",
            "\n",
            "Epoch 30000: Loss = 0.005333491135388613\n",
            "\n",
            "Validation loss: tensor(0.0078) \n",
            "\n",
            "Epoch 40000: Loss = 0.0013408118393272161\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 50000: Loss = 0.001340560964308679\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 60000: Loss = 0.0013403147459030151\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 70000: Loss = 0.0013402494369074702\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 80000: Loss = 0.0013407563092187047\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 90000: Loss = 0.0013399837771430612\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 100000: Loss = 0.0013399459421634674\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 110000: Loss = 0.0014197583077475429\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 120000: Loss = 0.0013398841256275773\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 130000: Loss = 0.0013399176532402635\n",
            "\n",
            "Validation loss: tensor(0.0035) \n",
            "\n",
            "Epoch 140000: Loss = 0.0013400665484368801\n",
            "\n",
            "Validation loss: tensor(0.0034) \n",
            "\n",
            "Epoch 150000: Loss = 0.0013399833114817739\n",
            "\n",
            "Validation loss: tensor(0.0034) \n",
            "\n",
            "Epoch 160000: Loss = 0.003060681279748678\n",
            "\n",
            "Validation loss: tensor(0.0042) \n",
            "\n",
            "Epoch 170000: Loss = 0.0013397539732977748\n",
            "\n",
            "Validation loss: tensor(0.0034) \n",
            "\n",
            "Epoch 180000: Loss = 0.001366095500998199\n",
            "\n",
            "Validation loss: tensor(0.0034) \n",
            "\n",
            "Epoch 190000: Loss = 0.001371229998767376\n",
            "\n",
            "Validation loss: tensor(0.0034) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 14/24 [28:34<23:18, 139.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.0013396248687058687\n",
            "\n",
            "Validation loss: tensor(0.0033) \n",
            "\n",
            "Epoch 10000: Loss = 0.3999508321285248\n",
            "\n",
            "Validation loss: tensor(0.3957) \n",
            "\n",
            "Epoch 20000: Loss = 0.3748779296875\n",
            "\n",
            "Validation loss: tensor(0.3713) \n",
            "\n",
            "Epoch 30000: Loss = 0.3478834629058838\n",
            "\n",
            "Validation loss: tensor(0.3410) \n",
            "\n",
            "Epoch 40000: Loss = 0.3213252127170563\n",
            "\n",
            "Validation loss: tensor(0.3119) \n",
            "\n",
            "Epoch 50000: Loss = 0.3095144033432007\n",
            "\n",
            "Validation loss: tensor(0.2974) \n",
            "\n",
            "Epoch 60000: Loss = 0.30799567699432373\n",
            "\n",
            "Validation loss: tensor(0.2936) \n",
            "\n",
            "Epoch 70000: Loss = 0.3079357445240021\n",
            "\n",
            "Validation loss: tensor(0.2891) \n",
            "\n",
            "Epoch 80000: Loss = 0.3078996539115906\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 90000: Loss = 0.3078937232494354\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 100000: Loss = 0.3078916370868683\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 110000: Loss = 0.307890921831131\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 120000: Loss = 0.3078906834125519\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 130000: Loss = 0.30789077281951904\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 140000: Loss = 0.30789148807525635\n",
            "\n",
            "Validation loss: tensor(0.2930) \n",
            "\n",
            "Epoch 150000: Loss = 0.30789148807525635\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 160000: Loss = 0.3078906238079071\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 170000: Loss = 0.30789074301719666\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 180000: Loss = 0.30789080262184143\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 190000: Loss = 0.30789101123809814\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 15/24 [31:24<22:21, 149.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.3078908920288086\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 10000: Loss = 0.3321039080619812\n",
            "\n",
            "Validation loss: tensor(0.3226) \n",
            "\n",
            "Epoch 20000: Loss = 0.2783762812614441\n",
            "\n",
            "Validation loss: tensor(0.2676) \n",
            "\n",
            "Epoch 30000: Loss = 0.21613386273384094\n",
            "\n",
            "Validation loss: tensor(0.2159) \n",
            "\n",
            "Epoch 40000: Loss = 0.11097113788127899\n",
            "\n",
            "Validation loss: tensor(0.1201) \n",
            "\n",
            "Epoch 50000: Loss = 0.03822356462478638\n",
            "\n",
            "Validation loss: tensor(0.0567) \n",
            "\n",
            "Epoch 60000: Loss = 0.020912375301122665\n",
            "\n",
            "Validation loss: tensor(0.0369) \n",
            "\n",
            "Epoch 70000: Loss = 0.009568911045789719\n",
            "\n",
            "Validation loss: tensor(0.0213) \n",
            "\n",
            "Epoch 80000: Loss = 0.002798283938318491\n",
            "\n",
            "Validation loss: tensor(0.0107) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 16/24 [32:58<17:40, 132.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.30828213691711426\n",
            "\n",
            "Validation loss: tensor(0.2943) \n",
            "\n",
            "Epoch 20000: Loss = 0.30815884470939636\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 30000: Loss = 0.30814650654792786\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 40000: Loss = 0.30814629793167114\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 50000: Loss = 0.3081466555595398\n",
            "\n",
            "Validation loss: tensor(0.2932) \n",
            "\n",
            "Epoch 60000: Loss = 0.0071901618503034115\n",
            "\n",
            "Validation loss: tensor(0.0141) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 17/24 [34:07<13:12, 113.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.4614357650279999\n",
            "\n",
            "Validation loss: tensor(0.4907) \n",
            "\n",
            "Epoch 20000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5209) \n",
            "\n",
            "Epoch 30000: Loss = 0.48075413703918457\n",
            "\n",
            "Validation loss: tensor(0.5173) \n",
            "\n",
            "Epoch 40000: Loss = 0.48076415061950684\n",
            "\n",
            "Validation loss: tensor(0.5170) \n",
            "\n",
            "Epoch 50000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5150) \n",
            "\n",
            "Epoch 60000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5155) \n",
            "\n",
            "Epoch 70000: Loss = 0.4807506799697876\n",
            "\n",
            "Validation loss: tensor(0.5165) \n",
            "\n",
            "Epoch 80000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5207) \n",
            "\n",
            "Epoch 90000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5218) \n",
            "\n",
            "Epoch 100000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5221) \n",
            "\n",
            "Epoch 110000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 120000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 130000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 140000: Loss = 0.4807503819465637\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 150000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 160000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 170000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 180000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 190000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 18/24 [39:39<17:55, 179.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.48075035214424133\n",
            "\n",
            "Validation loss: tensor(0.5222) \n",
            "\n",
            "Epoch 10000: Loss = 0.3078964352607727\n",
            "\n",
            "Validation loss: tensor(0.2939) \n",
            "\n",
            "Epoch 20000: Loss = 0.310593843460083\n",
            "\n",
            "Validation loss: tensor(0.2893) \n",
            "\n",
            "Epoch 30000: Loss = 0.03779987245798111\n",
            "\n",
            "Validation loss: tensor(0.0635) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 19/24 [40:17<11:24, 136.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.042356785386800766\n",
            "\n",
            "Validation loss: tensor(0.0653) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 20/24 [40:35<06:44, 101.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.30792495608329773\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 20000: Loss = 0.30792367458343506\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 30000: Loss = 0.3079867660999298\n",
            "\n",
            "Validation loss: tensor(0.2970) \n",
            "\n",
            "Epoch 40000: Loss = 0.046373672783374786\n",
            "\n",
            "Validation loss: tensor(0.0702) \n",
            "\n",
            "Epoch 50000: Loss = 0.042078446596860886\n",
            "\n",
            "Validation loss: tensor(0.0701) \n",
            "\n",
            "Epoch 60000: Loss = 0.04207821190357208\n",
            "\n",
            "Validation loss: tensor(0.0704) \n",
            "\n",
            "Epoch 70000: Loss = 0.04207802191376686\n",
            "\n",
            "Validation loss: tensor(0.0705) \n",
            "\n",
            "Epoch 80000: Loss = 0.042078081518411636\n",
            "\n",
            "Validation loss: tensor(0.0705) \n",
            "\n",
            "Epoch 90000: Loss = 0.04207794368267059\n",
            "\n",
            "Validation loss: tensor(0.0704) \n",
            "\n",
            "Epoch 100000: Loss = 0.06083712726831436\n",
            "\n",
            "Validation loss: tensor(0.0660) \n",
            "\n",
            "Epoch 110000: Loss = 0.04207802936434746\n",
            "\n",
            "Validation loss: tensor(0.0704) \n",
            "\n",
            "Epoch 120000: Loss = 0.04207806661725044\n",
            "\n",
            "Validation loss: tensor(0.0704) \n",
            "\n",
            "Epoch 130000: Loss = 0.0420781709253788\n",
            "\n",
            "Validation loss: tensor(0.0703) \n",
            "\n",
            "Epoch 140000: Loss = 0.04207819327712059\n",
            "\n",
            "Validation loss: tensor(0.0704) \n",
            "\n",
            "Epoch 150000: Loss = 0.042081307619810104\n",
            "\n",
            "Validation loss: tensor(0.0705) \n",
            "\n",
            "Epoch 160000: Loss = 0.04207858070731163\n",
            "\n",
            "Validation loss: tensor(0.0705) \n",
            "\n",
            "Epoch 170000: Loss = 0.04207700118422508\n",
            "\n",
            "Validation loss: tensor(0.0706) \n",
            "\n",
            "Epoch 180000: Loss = 0.042077019810676575\n",
            "\n",
            "Validation loss: tensor(0.0706) \n",
            "\n",
            "Epoch 190000: Loss = 0.042077451944351196\n",
            "\n",
            "Validation loss: tensor(0.0706) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 21/24 [43:56<06:32, 130.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.04207723215222359\n",
            "\n",
            "Validation loss: tensor(0.0707) \n",
            "\n",
            "Epoch 10000: Loss = 0.04506990313529968\n",
            "\n",
            "Validation loss: tensor(0.0738) \n",
            "\n",
            "Epoch 20000: Loss = 0.03803585097193718\n",
            "\n",
            "Validation loss: tensor(0.0702) \n",
            "\n",
            "Epoch 30000: Loss = 0.01866924576461315\n",
            "\n",
            "Validation loss: tensor(0.0331) \n",
            "\n",
            "Epoch 40000: Loss = 0.0017757081659510732\n",
            "\n",
            "Validation loss: tensor(0.0089) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 22/24 [44:51<03:36, 108.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.3223130702972412\n",
            "\n",
            "Validation loss: tensor(0.3127) \n",
            "\n",
            "Epoch 20000: Loss = 0.3079793453216553\n",
            "\n",
            "Validation loss: tensor(0.2936) \n",
            "\n",
            "Epoch 30000: Loss = 0.3079383671283722\n",
            "\n",
            "Validation loss: tensor(0.2916) \n",
            "\n",
            "Epoch 40000: Loss = 0.3078867495059967\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 50000: Loss = 0.3078864812850952\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 60000: Loss = 0.3078860938549042\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 70000: Loss = 0.3078862428665161\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 80000: Loss = 0.3078862428665161\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 90000: Loss = 0.30788615345954895\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 100000: Loss = 0.3078862130641937\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 110000: Loss = 0.3078859746456146\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 120000: Loss = 0.3078859746456146\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 130000: Loss = 0.3078863024711609\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 140000: Loss = 0.3078858554363251\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 150000: Loss = 0.30788618326187134\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 160000: Loss = 0.3078862428665161\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 170000: Loss = 0.30788612365722656\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 180000: Loss = 0.30788639187812805\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 190000: Loss = 0.3078860938549042\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 23/24 [48:01<02:12, 132.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.3078862428665161\n",
            "\n",
            "Validation loss: tensor(0.2934) \n",
            "\n",
            "Epoch 10000: Loss = 0.2828729450702667\n",
            "\n",
            "Validation loss: tensor(0.2726) \n",
            "\n",
            "Epoch 20000: Loss = 0.11232065409421921\n",
            "\n",
            "Validation loss: tensor(0.1227) \n",
            "\n",
            "Epoch 30000: Loss = 0.04219088703393936\n",
            "\n",
            "Validation loss: tensor(0.0691) \n",
            "\n",
            "Epoch 40000: Loss = 0.04202703386545181\n",
            "\n",
            "Validation loss: tensor(0.0688) \n",
            "\n",
            "Epoch 50000: Loss = 0.04203357174992561\n",
            "\n",
            "Validation loss: tensor(0.0686) \n",
            "\n",
            "Epoch 60000: Loss = 0.042024657130241394\n",
            "\n",
            "Validation loss: tensor(0.0694) \n",
            "\n",
            "Epoch 70000: Loss = 0.04202236980199814\n",
            "\n",
            "Validation loss: tensor(0.0690) \n",
            "\n",
            "Epoch 80000: Loss = 0.042026031762361526\n",
            "\n",
            "Validation loss: tensor(0.0688) \n",
            "\n",
            "Epoch 90000: Loss = 0.04202183336019516\n",
            "\n",
            "Validation loss: tensor(0.0691) \n",
            "\n",
            "Epoch 100000: Loss = 0.04203176870942116\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 110000: Loss = 0.042026445269584656\n",
            "\n",
            "Validation loss: tensor(0.0688) \n",
            "\n",
            "Epoch 120000: Loss = 0.04204060509800911\n",
            "\n",
            "Validation loss: tensor(0.0698) \n",
            "\n",
            "Epoch 130000: Loss = 0.042096398770809174\n",
            "\n",
            "Validation loss: tensor(0.0680) \n",
            "\n",
            "Epoch 140000: Loss = 0.04203101620078087\n",
            "\n",
            "Validation loss: tensor(0.0686) \n",
            "\n",
            "Epoch 150000: Loss = 0.042053379118442535\n",
            "\n",
            "Validation loss: tensor(0.0700) \n",
            "\n",
            "Epoch 160000: Loss = 0.042022086679935455\n",
            "\n",
            "Validation loss: tensor(0.0689) \n",
            "\n",
            "Epoch 170000: Loss = 0.04203317314386368\n",
            "\n",
            "Validation loss: tensor(0.0696) \n",
            "\n",
            "Epoch 180000: Loss = 0.042025402188301086\n",
            "\n",
            "Validation loss: tensor(0.0695) \n",
            "\n",
            "Epoch 190000: Loss = 0.04202050715684891\n",
            "\n",
            "Validation loss: tensor(0.0690) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [52:26<00:00, 131.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200000: Loss = 0.04202287271618843\n",
            "\n",
            "Validation loss: tensor(0.0689) \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# loop for possible hyperparameter combinations with Adam optimizer\n",
        "\n",
        "# iterates over possible combinations of hidden size, learning rate and number of hidden layers\n",
        "\n",
        "for hsize, lr, num_hidden_lay in tqdm(hparam_list_adam):\n",
        "    seed = 42\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    model, criterion, optimizer = create_net_loss_optim(hsize, num_hidden_lay, \"adam\", lr)\n",
        "    losses, vallosses, epoch, _ = _train(x_train, y_train, criterion, optimizer, model)\n",
        "\n",
        "    results.append(\n",
        "        {\n",
        "            \"num_hidden_layer\": num_hidden_lay,\n",
        "            \"hiddensize\": hsize,\n",
        "            \"lr\": lr,\n",
        "            \"optimizer\": \"Adam\",\n",
        "            \"momentum\": \"-\",\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": losses,\n",
        "            \"val_loss\": vallosses,\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCOKbYZmvGLq"
      },
      "source": [
        "### results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Iq-Q_FEvM67"
      },
      "outputs": [],
      "source": [
        "# import pandas to create dataframe of test results\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySww179NvHsE"
      },
      "outputs": [],
      "source": [
        "# create dataframe of results\n",
        "\n",
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4wS8BLUt6zkn",
        "outputId": "99ff3db8-83d5-40ed-8c38-02a7c9516ec6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d5e1068b-1de3-4df4-9992-6f3b73d290db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_hidden_layer</th>\n",
              "      <th>hiddensize</th>\n",
              "      <th>lr</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>momentum</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.9</td>\n",
              "      <td>200000</td>\n",
              "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
              "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200000</td>\n",
              "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
              "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.9</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.4807995855808258, 0.4807503819465637, 0.480...</td>\n",
              "      <td>[0.5126284956932068, 0.5150364637374878, 0.515...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.4814976751804352, 0.48071926832199097, 0.48...</td>\n",
              "      <td>[0.5073033571243286, 0.5145055651664734, 0.515...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.9</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.43145495653152466, 0.401265412569046, 0.396...</td>\n",
              "      <td>[0.4215555191040039, 0.3992640972137451, 0.398...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>12700</td>\n",
              "      <td>[0.39640793204307556, 0.3836542069911957, 0.38...</td>\n",
              "      <td>[0.39511021971702576, 0.3824705481529236, 0.41...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.42759618163108826, 0.40552225708961487, 0.3...</td>\n",
              "      <td>[0.41391265392303467, 0.39689457416534424, 0.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>41900</td>\n",
              "      <td>[0.41976433992385864, 0.3955680727958679, 0.38...</td>\n",
              "      <td>[0.4091905951499939, 0.3873811960220337, 0.375...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.47402533888816833, 0.45887720584869385, 0.4...</td>\n",
              "      <td>[0.45313000679016113, 0.4398030936717987, 0.43...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.4700932204723358, 0.45846447348594666, 0.44...</td>\n",
              "      <td>[0.45304176211357117, 0.44022896885871887, 0.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5e1068b-1de3-4df4-9992-6f3b73d290db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5e1068b-1de3-4df4-9992-6f3b73d290db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5e1068b-1de3-4df4-9992-6f3b73d290db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    num_hidden_layer  hiddensize       lr optimizer momentum   epoch  \\\n",
              "0                  1          25  0.01000       SGD      0.9  200000   \n",
              "1                  1          25  0.01000       SGD      0.0  200000   \n",
              "2                  2          25  0.01000       SGD      0.9  200000   \n",
              "3                  2          25  0.01000       SGD      0.0  200000   \n",
              "4                  1          25  0.00100       SGD      0.9  200000   \n",
              "..               ...         ...      ...       ...      ...     ...   \n",
              "67                 2         100  0.00100      Adam        -   12700   \n",
              "68                 1         100  0.00010      Adam        -  200000   \n",
              "69                 2         100  0.00010      Adam        -   41900   \n",
              "70                 1         100  0.00001      Adam        -  200000   \n",
              "71                 2         100  0.00001      Adam        -  200000   \n",
              "\n",
              "                                           train_loss  \\\n",
              "0   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
              "1   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
              "2   [0.4807995855808258, 0.4807503819465637, 0.480...   \n",
              "3   [0.4814976751804352, 0.48071926832199097, 0.48...   \n",
              "4   [0.43145495653152466, 0.401265412569046, 0.396...   \n",
              "..                                                ...   \n",
              "67  [0.39640793204307556, 0.3836542069911957, 0.38...   \n",
              "68  [0.42759618163108826, 0.40552225708961487, 0.3...   \n",
              "69  [0.41976433992385864, 0.3955680727958679, 0.38...   \n",
              "70  [0.47402533888816833, 0.45887720584869385, 0.4...   \n",
              "71  [0.4700932204723358, 0.45846447348594666, 0.44...   \n",
              "\n",
              "                                             val_loss  \n",
              "0   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
              "1   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
              "2   [0.5126284956932068, 0.5150364637374878, 0.515...  \n",
              "3   [0.5073033571243286, 0.5145055651664734, 0.515...  \n",
              "4   [0.4215555191040039, 0.3992640972137451, 0.398...  \n",
              "..                                                ...  \n",
              "67  [0.39511021971702576, 0.3824705481529236, 0.41...  \n",
              "68  [0.41391265392303467, 0.39689457416534424, 0.3...  \n",
              "69  [0.4091905951499939, 0.3873811960220337, 0.375...  \n",
              "70  [0.45313000679016113, 0.4398030936717987, 0.43...  \n",
              "71  [0.45304176211357117, 0.44022896885871887, 0.4...  \n",
              "\n",
              "[72 rows x 8 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0cDOICJQd_H"
      },
      "outputs": [],
      "source": [
        "# adding a column of recorded final loss before convergence (or max number of epochs)\n",
        "# for training and validation set\n",
        "\n",
        "results_df[\"final_train_loss\"] = [i[-1] for i in results_df[\"train_loss\"]]\n",
        "results_df[\"final_test_loss\"] = [i[-1] for i in results_df[\"val_loss\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "eSYRfDx5Qrct",
        "outputId": "4f66d4ac-a628-4162-a0be-e8690f67e1a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-da9d70d7-8ee3-4684-b41c-34226aed125d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_hidden_layer</th>\n",
              "      <th>hiddensize</th>\n",
              "      <th>lr</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>momentum</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>final_train_loss</th>\n",
              "      <th>final_test_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.9</td>\n",
              "      <td>200000</td>\n",
              "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
              "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200000</td>\n",
              "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
              "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.9</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.4807995855808258, 0.4807503819465637, 0.480...</td>\n",
              "      <td>[0.5126284956932068, 0.5150364637374878, 0.515...</td>\n",
              "      <td>0.480750</td>\n",
              "      <td>0.515053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.4814976751804352, 0.48071926832199097, 0.48...</td>\n",
              "      <td>[0.5073033571243286, 0.5145055651664734, 0.515...</td>\n",
              "      <td>0.480750</td>\n",
              "      <td>0.515208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.9</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.43145495653152466, 0.401265412569046, 0.396...</td>\n",
              "      <td>[0.4215555191040039, 0.3992640972137451, 0.398...</td>\n",
              "      <td>0.394193</td>\n",
              "      <td>0.394566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>12700</td>\n",
              "      <td>[0.39640793204307556, 0.3836542069911957, 0.38...</td>\n",
              "      <td>[0.39511021971702576, 0.3824705481529236, 0.41...</td>\n",
              "      <td>0.000852</td>\n",
              "      <td>0.002578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.42759618163108826, 0.40552225708961487, 0.3...</td>\n",
              "      <td>[0.41391265392303467, 0.39689457416534424, 0.3...</td>\n",
              "      <td>0.042077</td>\n",
              "      <td>0.070682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>41900</td>\n",
              "      <td>[0.41976433992385864, 0.3955680727958679, 0.38...</td>\n",
              "      <td>[0.4091905951499939, 0.3873811960220337, 0.375...</td>\n",
              "      <td>0.000976</td>\n",
              "      <td>0.008107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.47402533888816833, 0.45887720584869385, 0.4...</td>\n",
              "      <td>[0.45313000679016113, 0.4398030936717987, 0.43...</td>\n",
              "      <td>0.307886</td>\n",
              "      <td>0.293354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.4700932204723358, 0.45846447348594666, 0.44...</td>\n",
              "      <td>[0.45304176211357117, 0.44022896885871887, 0.4...</td>\n",
              "      <td>0.042023</td>\n",
              "      <td>0.068869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da9d70d7-8ee3-4684-b41c-34226aed125d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da9d70d7-8ee3-4684-b41c-34226aed125d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da9d70d7-8ee3-4684-b41c-34226aed125d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    num_hidden_layer  hiddensize       lr optimizer momentum   epoch  \\\n",
              "0                  1          25  0.01000       SGD      0.9  200000   \n",
              "1                  1          25  0.01000       SGD      0.0  200000   \n",
              "2                  2          25  0.01000       SGD      0.9  200000   \n",
              "3                  2          25  0.01000       SGD      0.0  200000   \n",
              "4                  1          25  0.00100       SGD      0.9  200000   \n",
              "..               ...         ...      ...       ...      ...     ...   \n",
              "67                 2         100  0.00100      Adam        -   12700   \n",
              "68                 1         100  0.00010      Adam        -  200000   \n",
              "69                 2         100  0.00010      Adam        -   41900   \n",
              "70                 1         100  0.00001      Adam        -  200000   \n",
              "71                 2         100  0.00001      Adam        -  200000   \n",
              "\n",
              "                                           train_loss  \\\n",
              "0   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
              "1   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
              "2   [0.4807995855808258, 0.4807503819465637, 0.480...   \n",
              "3   [0.4814976751804352, 0.48071926832199097, 0.48...   \n",
              "4   [0.43145495653152466, 0.401265412569046, 0.396...   \n",
              "..                                                ...   \n",
              "67  [0.39640793204307556, 0.3836542069911957, 0.38...   \n",
              "68  [0.42759618163108826, 0.40552225708961487, 0.3...   \n",
              "69  [0.41976433992385864, 0.3955680727958679, 0.38...   \n",
              "70  [0.47402533888816833, 0.45887720584869385, 0.4...   \n",
              "71  [0.4700932204723358, 0.45846447348594666, 0.44...   \n",
              "\n",
              "                                             val_loss  final_train_loss  \\\n",
              "0   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...               NaN   \n",
              "1   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...               NaN   \n",
              "2   [0.5126284956932068, 0.5150364637374878, 0.515...          0.480750   \n",
              "3   [0.5073033571243286, 0.5145055651664734, 0.515...          0.480750   \n",
              "4   [0.4215555191040039, 0.3992640972137451, 0.398...          0.394193   \n",
              "..                                                ...               ...   \n",
              "67  [0.39511021971702576, 0.3824705481529236, 0.41...          0.000852   \n",
              "68  [0.41391265392303467, 0.39689457416534424, 0.3...          0.042077   \n",
              "69  [0.4091905951499939, 0.3873811960220337, 0.375...          0.000976   \n",
              "70  [0.45313000679016113, 0.4398030936717987, 0.43...          0.307886   \n",
              "71  [0.45304176211357117, 0.44022896885871887, 0.4...          0.042023   \n",
              "\n",
              "    final_test_loss  \n",
              "0               NaN  \n",
              "1               NaN  \n",
              "2          0.515053  \n",
              "3          0.515208  \n",
              "4          0.394566  \n",
              "..              ...  \n",
              "67         0.002578  \n",
              "68         0.070682  \n",
              "69         0.008107  \n",
              "70         0.293354  \n",
              "71         0.068869  \n",
              "\n",
              "[72 rows x 10 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm0LasTWQzAr"
      },
      "outputs": [],
      "source": [
        "# save the results in case of need to examine\n",
        "# results_df.to_csv(\"/content/drive/MyDrive/courses/spring2023/CS 515 - Deep Learning/HW-1/results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "TUST1G9aRIp8",
        "outputId": "927b61f1-94a6-4a32-b406-20fdea6eb7f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5979b00a-32d3-41f1-b79b-db4f17fa84c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_hidden_layer</th>\n",
              "      <th>hiddensize</th>\n",
              "      <th>lr</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>momentum</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>final_train_loss</th>\n",
              "      <th>final_test_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>23600</td>\n",
              "      <td>[0.4201847016811371, 0.367850124835968, 0.3436...</td>\n",
              "      <td>[0.41013476252555847, 0.3597658574581146, 0.34...</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>0.002241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>12700</td>\n",
              "      <td>[0.39640793204307556, 0.3836542069911957, 0.38...</td>\n",
              "      <td>[0.39511021971702576, 0.3824705481529236, 0.41...</td>\n",
              "      <td>0.000852</td>\n",
              "      <td>0.002578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>38300</td>\n",
              "      <td>[0.41055724024772644, 0.35794392228126526, 0.3...</td>\n",
              "      <td>[0.3998727798461914, 0.3498906195163727, 0.343...</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>0.002882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>7400</td>\n",
              "      <td>[0.378065288066864, 0.321720689535141, 0.29810...</td>\n",
              "      <td>[0.37884166836738586, 0.3140155076980591, 0.28...</td>\n",
              "      <td>0.000857</td>\n",
              "      <td>0.002957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>200000</td>\n",
              "      <td>[0.4481789767742157, 0.42912811040878296, 0.41...</td>\n",
              "      <td>[0.4469815492630005, 0.4154033958911896, 0.401...</td>\n",
              "      <td>0.001340</td>\n",
              "      <td>0.003313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>73800</td>\n",
              "      <td>[0.4119745194911957, 0.3970228433609009, 0.394...</td>\n",
              "      <td>[0.40479880571365356, 0.39669281244277954, 0.3...</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.003430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.9</td>\n",
              "      <td>187800</td>\n",
              "      <td>[0.43894532322883606, 0.4232856035232544, 0.41...</td>\n",
              "      <td>[0.42305809259414673, 0.41384249925613403, 0.4...</td>\n",
              "      <td>0.000999</td>\n",
              "      <td>0.003475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>71600</td>\n",
              "      <td>[0.350483775138855, 0.3168136775493622, 0.3124...</td>\n",
              "      <td>[0.3548557162284851, 0.3080942928791046, 0.295...</td>\n",
              "      <td>0.000920</td>\n",
              "      <td>0.003532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>61300</td>\n",
              "      <td>[0.45874515175819397, 0.4208605885505676, 0.36...</td>\n",
              "      <td>[0.45055684447288513, 0.41846534609794617, 0.3...</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.003904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>Adam</td>\n",
              "      <td>-</td>\n",
              "      <td>21600</td>\n",
              "      <td>[0.4476813077926636, 0.4389364719390869, 0.431...</td>\n",
              "      <td>[0.4323185384273529, 0.42527201771736145, 0.41...</td>\n",
              "      <td>0.000995</td>\n",
              "      <td>0.003993</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5979b00a-32d3-41f1-b79b-db4f17fa84c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5979b00a-32d3-41f1-b79b-db4f17fa84c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5979b00a-32d3-41f1-b79b-db4f17fa84c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    num_hidden_layer  hiddensize      lr optimizer momentum   epoch  \\\n",
              "59                 2          50  0.0010      Adam        -   23600   \n",
              "67                 2         100  0.0010      Adam        -   12700   \n",
              "66                 1         100  0.0010      Adam        -   38300   \n",
              "57                 2          50  0.0100      Adam        -    7400   \n",
              "61                 2          50  0.0001      Adam        -  200000   \n",
              "51                 2          25  0.0010      Adam        -   73800   \n",
              "42                 2         100  0.0001       SGD      0.9  187800   \n",
              "49                 2          25  0.0100      Adam        -   71600   \n",
              "64                 1         100  0.0100      Adam        -   61300   \n",
              "53                 2          25  0.0001      Adam        -   21600   \n",
              "\n",
              "                                           train_loss  \\\n",
              "59  [0.4201847016811371, 0.367850124835968, 0.3436...   \n",
              "67  [0.39640793204307556, 0.3836542069911957, 0.38...   \n",
              "66  [0.41055724024772644, 0.35794392228126526, 0.3...   \n",
              "57  [0.378065288066864, 0.321720689535141, 0.29810...   \n",
              "61  [0.4481789767742157, 0.42912811040878296, 0.41...   \n",
              "51  [0.4119745194911957, 0.3970228433609009, 0.394...   \n",
              "42  [0.43894532322883606, 0.4232856035232544, 0.41...   \n",
              "49  [0.350483775138855, 0.3168136775493622, 0.3124...   \n",
              "64  [0.45874515175819397, 0.4208605885505676, 0.36...   \n",
              "53  [0.4476813077926636, 0.4389364719390869, 0.431...   \n",
              "\n",
              "                                             val_loss  final_train_loss  \\\n",
              "59  [0.41013476252555847, 0.3597658574581146, 0.34...          0.000815   \n",
              "67  [0.39511021971702576, 0.3824705481529236, 0.41...          0.000852   \n",
              "66  [0.3998727798461914, 0.3498906195163727, 0.343...          0.000996   \n",
              "57  [0.37884166836738586, 0.3140155076980591, 0.28...          0.000857   \n",
              "61  [0.4469815492630005, 0.4154033958911896, 0.401...          0.001340   \n",
              "51  [0.40479880571365356, 0.39669281244277954, 0.3...          0.000890   \n",
              "42  [0.42305809259414673, 0.41384249925613403, 0.4...          0.000999   \n",
              "49  [0.3548557162284851, 0.3080942928791046, 0.295...          0.000920   \n",
              "64  [0.45055684447288513, 0.41846534609794617, 0.3...          0.000930   \n",
              "53  [0.4323185384273529, 0.42527201771736145, 0.41...          0.000995   \n",
              "\n",
              "    final_test_loss  \n",
              "59         0.002241  \n",
              "67         0.002578  \n",
              "66         0.002882  \n",
              "57         0.002957  \n",
              "61         0.003313  \n",
              "51         0.003430  \n",
              "42         0.003475  \n",
              "49         0.003532  \n",
              "64         0.003904  \n",
              "53         0.003993  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sorting the results in ascending order according to train and val loss\n",
        "# print the first 10 results from sorted df to see best 10 results\n",
        "results_df.sort_values(by=[\"final_test_loss\", \"final_train_loss\"])[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG92gh2rS1qS",
        "outputId": "2d8077af-6543-4fc6-8e5c-7af8e637098e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'num_hidden_layer': 2,\n",
              " 'hiddensize': 50,\n",
              " 'lr': 0.001,\n",
              " 'optimizer': 'Adam',\n",
              " 'momentum': '-',\n",
              " 'epoch': 23600,\n",
              " 'final_train_loss': 0.000815198349300772,\n",
              " 'final_test_loss': 0.0022407539654523134}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# getting the best hyperparams from the best test results to use it on final training\n",
        "\n",
        "best_params = results_df.sort_values(by=[\"final_test_loss\", \"final_train_loss\"]).iloc[0].to_dict()\n",
        "best_params.pop(\"train_loss\")\n",
        "best_params.pop(\"val_loss\")\n",
        "best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N806eWVStO5a"
      },
      "source": [
        "### final model training - best hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "BIC6CEEStU3b",
        "outputId": "9706dc18-b453-4c53-a999-ead4e6200412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10000: Loss = 0.3079068064689636\n",
            "\n",
            "Validation loss: tensor(0.2933) \n",
            "\n",
            "Epoch 20000: Loss = 0.017645638436079025\n",
            "\n",
            "Validation loss: tensor(0.0256) \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "final_model, criterion, optimizer = create_net_loss_optim(best_params[\"hiddensize\"],\n",
        "                                                          best_params[\"num_hidden_layer\"],\n",
        "                                                          best_params[\"optimizer\"].lower(),\n",
        "                                                          best_params[\"lr\"],\n",
        "                                                          best_params[\"momentum\"],\n",
        "                                                          )\n",
        "losses, vallosses, _, final_model = _train(x_train, y_train, criterion, optimizer, final_model)\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.plot(vallosses)\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx8aFiO8GlJJ"
      },
      "source": [
        "## Test the final model on train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "5_sxlpChratS",
        "outputId": "65b9dad5-f135-4e44-afd1-ad1839418670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE on Training Set = 0.0008145284373313189\n",
            "MSE on Test Set = 0.0022407539654523134\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test the neural network with train data ---------------------\n",
        "with torch.no_grad():\n",
        "    y_pred = final_model(x_train) # make a forward pass on the train data\n",
        "\n",
        "loss = criterion(y_pred, y_train) # calculate the loss\n",
        "print(\"MSE on Training Set = {}\".format(loss.item()))\n",
        "\n",
        "#lets see the generalization error ----------------------------\n",
        "# Test the neural network with val data\n",
        "with torch.no_grad():\n",
        "    y_pred = final_model(x_test) # make a forward pass on the test data\n",
        "\n",
        "valloss = criterion(y_pred, y_test) # calculate the loss\n",
        "print(\"MSE on Test Set = {}\".format(valloss.item()))\n",
        "\n",
        "# Plot the test data & predictions -----------------------------\n",
        "plt.scatter(x_test.numpy(), y_test.numpy(), label='Test Data')\n",
        "plt.scatter(x_test.numpy(), y_pred.numpy(), label='Predictions')\n",
        "\n",
        "plt.title(\"Test Data and Predictions\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
